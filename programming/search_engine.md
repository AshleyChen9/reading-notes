# 搜索引擎
![cover](https://img3.doubanio.com/lpic/s6176453.jpg)

[豆瓣链接](https://book.douban.com/subject/4861766/)

    作者: W.Bruce Croft / Donald Metzler / Trevor Strohman
    出版社: 机械工业出版社
    副标题: 信息检索实践
    原作名: Search Engines : Information Retrieval in Practice
    译者: 刘挺 / 秦兵 / 张宇 / 车万翔
    出版年: 2010-6-1
    页数: 309
    定价: 56.00元
    装帧: 平装
    丛书: 计算机科学丛书
    ISBN: 9787111288084

# 2.搜索引擎架构
## 2.1 什么是软件架构
搜索引擎的两个主要目的
- 效果（质量）
- 效率（速度）

## 2.2 基本的构件
- 索引处理(indexing process)
  - 文本采集(text acquisition)
  - 文本转换(text transformation)：将文档转换为索引项(index term)或特征(feature)。
  - 索引创建(index creation)
- 查询处理(query process)
  - 用户交互(user interaction)
  - 排序(ranking)
  - 评价(evaluation)：一个重要的任务是利用日志数据来记录和分析用户的行为。

## 2.3 组件及其功能
### 2.3.1 文本采集
1. 爬虫(crawler)
2. 信息源(feed):RSS
3. 转换
  - 将HTML,XML,PDF,WORD,PPT转换成统一格式和文档的元数据格式。
  - 保证它们使用统一的编码方案进行转换。
4. 文档数据库

### 2.3.2 文本转换
1. 解析器：处理文本词素(token)序列，词素切分。
2. 停用词去除
3. 词干提取器(stemmer)把同一个词干(stem)得到的派生词进行归类。
4. 超链接抽取和分析
5. 信息抽取：抽取句法特征，如名词短语，需要某种形式的句法分析和词性标注(part-of-speech tagging)。抽取具有指定语义内容的特征，例如，命名实体(named entity)识别器，识别如人名、公司名、日期和地点等。
6. 分类器
  - 给文档分配事先定义好的类别标签。
  - 判别一个文档是否是垃圾文档，以及识别文档中的广告。
  - 聚类用于事先没有定义类别标签的基础上，将相关文档聚集在一起。

### 2.3.3 索引的创建
1. 文档统计：简单汇总和记录词、特征及文档的统计信息。结果存在查找表(lookup table)。
  - 索引项在各文档中出现次数（词及更加复杂的特征）
  - 索引项在文档中出现位置
  - 索引项在一组文档（如标记“体育”）中出现次数
  - 按照词素数量统计文档长度
2. 加权：利用文档统计结果计算权值，并将权值存储在查找表中。如if·idf
3. 倒排(inversion):将文本转换组件传递过来的文档-词信息流转换为词项-文档信息，以便于建立倒排索引。
4. 索引分派：将索引分发给多台计算机。

### 2.3.4 用户交互
1. 查询输入
2. 查询转换：用于在生成好序的文档之前和之后改善初始查询。
  - 文本转换技术:在查询文本上，需要进行词素切分、停用词去除和词干提取。
  - 拼写检查(spell checking)和查询建议(query suggestion):向用户提供初始查询的一些候选查询，这些候选查询可能纠正了拼写错误或是对用户所需信息的更规范描述。
  - 查询扩展(query expansion):对查询进行推荐或增加一些额外的词项，在对文档中词项的出现情况分析的基础上进行。
  - 相关反馈(relevance feedback):一种查询扩展技术，利用用户认为相关的文档中出现的词项对查询进行扩展。
3. 结果输出
  - 生成网页摘要(snippets)
  - 强调(highlighting)文档中重要的词和段落
  - 对输出结果聚类以找到文档相关的类别
  - 将相应广告增加到结果中

### 2.3.5 排序
1. 打分机制
  - $\sum_iq_id_i$ ,qi是查询中第i个词项的权值，di是文档词项的权值。
2. 性能优化：降低系统的响应时间，提高查询吞吐量。
  - term-at-a-time
  - document-at-a-time
  - 安全的(safe)的优化方式与不安全的(unsafe)的优化方式
3. 分布式

### 2.3.6 评价
1. 日志
  - 点击日志(点击数据)
  - 驻留时间(dwell time)
2. 排序分析
3. 性能分析

# 3.信息采集与信息源
## 3.1 确定搜索内容
## 3.2 网络信息爬取
1. 抓取网页
2. 网络爬虫
3. 时新性
4. 面向主题的信息采集
5. 深层网络：那些爬虫很难找到的站点（deep Web，也称hidden Web）
  - 私人站点：没有任何指向它的链接
  - 表单结果
  - 脚本页面（JavaScript，Flash）
6. 网站地图(sitemap)
7. 分布式信息采集

## 3.3 文档和电子邮件采集
## 3.4 文档信息源
pull类型信息源常见RSS。

## 3.5 转换问题
## 3.6 存储文档
## 3.7 重复检测
- 完全重复文档检测：checksumming，含有相同字符当顺序不同，具有相同checksum。
- 考虑字符出现位置：cyclic redundancy check，CRC
- 近似重复检测：指纹（fingerprint），生成指纹过程：
  - 首先对文档进行分词。删除不是词的内容（空格，HTML标签等）。
  - 对于给定n，将这些词组合成n-gram。通常是相互重叠的词序列。
  - 其中的一些n-gram被选择用于表示该文档。
  - 对这些被选择的n-gram进行散列，以提高检索效率，并进一步减少文档表示的大小。
  - 将散列值进行存储。

## 3.8 去除噪声
Finn(2001):在网页中主要内容部分的文本会比网页中附加内容的文本含有更少量的HTML标签。

# 4.文本处理
## 4.1 从词到词项
- 搜索引擎之所以有效的原因，是文本的很多含义通过词语出现和共现的次数获得。
- 理解文本的统计性质是理解检索模型和排序算法的基础。

## 4.2 文本统计
- Zipf's Law:第r高频的词的出现次数与r成反比，或者说，一个词在词频统计表中的排名乘以它的词频(f)约等于一个常数(k):
  - $r \cdot f = k$
- Zipf 可表示为：$r \cdot P_r = c$
  - 其中$P_r$表示第r高频词出现的概率
  - c是一常数，对于英语而言，$c \approx 0.1$
- Zipf Law通常对排名靠前和靠后的预测不准确。
- $r \cdot P_r$值的log-log图呈现一条直线。
- Heaps(1978)发现，语料规模与词表大小的关系为：$v = k \cdot n^\beta$
  - v为词汇量大小
  - 语料中共有n个词
  - k和 $\beta$是随着不同语料变化的参数
  - Heaps法则预测当语料规模很小时，新词数量增长非常快。随着语料规模变大，新词数量无限增长，但是增速会变慢。
- 估计数据集和结果集大小
  - 假设词的出现彼此独立
    - $P(a \cap b \cap c) = P(a) \cdot P(b) \cdot P(c)$
    - $P(a) = \frac{f_a}{N}$
    - $P(b) = \frac{f_b}{N}$
    - $P(c) = \frac{f_c}{N}$
    - $f_{abc} = N \cdot \frac{f_a}{N} \cdot \frac{f_b}{N} \cdot \frac{f_c}{N}$
  - 假设词的出现不独立
    - $P(a \cap b \cap c) = P(a \cap b) \cdot P(c | a \cap b)$
  - 估计文档总数
    - $\frac{f_{ab}}{N} = \frac{f_a}{N} \cdot \frac{f_b}{N}$
    - $N = \frac{f_a \cdot f_b}{f_{ab}}$

## 文档解析
- 词素切分：指从文档中的字符序列中获取词的过程。
- 停用词去除
  - 停用词(stopword):第一，这些功能词极其普遍。第二，由于它们的普遍性和功能，这些词很少单独表达文档相关程度的信息。
- 词干提取（stemming）：获得一个词不同变形之间关系的文本处理过程。将一个词由变形（inflection）（如复数、时态）或者派生(derivation)产生的多种不同形式简化为一个共同的例子。
- 短语和n-gram
  - 词性标注器（part-of-speech tagger，POS）：根据上下文信息对文本中的每一个词赋予一个词性标记。一般的词性标记包括NN（单数名词）、NNS（复数名词）、VB（动词）、VBD（动词，过去时）、VBN（动词，过去分词）、IN（介词）、JJ（形容词）、CC（连词）、PRP（代词）和MD（情态动词）。
  - 任何n个词的序列都构成一个短语。这就是所谓n-gram。两个词的序列称为bigram，三个词的序列称为trigram。
  - 所有长度的n-gram构成一个Zipf分布，一些常见短语非常频繁，大量的酸雨只出现一次，n-gram（包括单个词）的“排名-频率”数据比只有词本身更符合Zipf分布。

## 文档结构和标记
- 从HTML tag得到的网页结构信息的有些部分，是排序算法用到的非常重要的特征。
- XML：XQuery

## 链接分析
### 锚文本
- 链接的锚文本集合可以作为链出网页额外的文本属性，可以在排序算法中使用。
- 写锚文本的人一般不是目标网页的作者。这意味着锚文本可能是从另一个角度来描述目标网页。

### PageRank
网页u的PageRank一般公式：

$PR(u) = \frac{\lambda}{N} + (1-\lambda) \cdot \sum_{v \in B_u} \frac{PR(v)}{L_v}$

- $B_u$：指向u的网页集合
- $L_v$：网页v中包含的外链数
- N：需要考虑的网页数
- $\lambda$：进入任何网页的概率，一般取0.15

这个公式也可表达为矩阵等式：R=TR,R是矩阵T的特征向量。

其中R为PageRank向量，T为随机游走模型转移概率矩阵。元素$T_{ij}$表示网页i进入网页j的概率，并且

$T_{ij}=\frac{\lambda}{N}+(1-\lambda)\frac{1}{L_i}$

## 信息抽取
命名实体识别（named entity recognition）：一个命名实体是表达特定应用感兴趣的某一个事物的词或词序列。最一般的例子是人名、公司名或机构名、地名、时间和日期表达式、数量和货币值。

    Fred Smith,who lives at 10 Water Street,Springfield,MA, is a long-time collector of tropical fish.

隐马尔可夫模型的信息抽取：给定一个句子，找到一个实体类别序列，使得产生这个句子的概率最大。自由状态转移时产生的输出是可见的（可以被观察到的）：潜在的状态是隐藏的（hidden）。

对于上面例子，识别器将找到：

    <start><name><not-an-entity><location><not-an-entity><end>

时，对于那个模型，其概率最高。Viterbi算法可以在HMM模型中找到最大概率的状态序列。

使用这种方法识别命名实体的核心问题是，句子模型中的概率必须从训练数据估计出来。为了估计转义和输出概率，使用人工标注了正确实体标签的文本作为训练数据。从这个训练数据，可以直接估计出某个类别产生词的概率（输出概率）和类别之间的转移概率。

## 国际化
字符编码是搜索引擎处理非英语语言时的核心问题。

词素切分对于很多语言很重要，有其是CJK家族。

# 5.基于索引的相关排序
