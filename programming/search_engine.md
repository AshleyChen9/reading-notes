# 搜索引擎
![cover](https://img3.doubanio.com/lpic/s6176453.jpg)

[豆瓣链接](https://book.douban.com/subject/4861766/)

    作者: W.Bruce Croft / Donald Metzler / Trevor Strohman
    出版社: 机械工业出版社
    副标题: 信息检索实践
    原作名: Search Engines : Information Retrieval in Practice
    译者: 刘挺 / 秦兵 / 张宇 / 车万翔
    出版年: 2010-6-1
    页数: 309
    定价: 56.00元
    装帧: 平装
    丛书: 计算机科学丛书
    ISBN: 9787111288084

# 2.搜索引擎架构
## 2.1 什么是软件架构
搜索引擎的两个主要目的
- 效果（质量）
- 效率（速度）

## 2.2 基本的构件
- 索引处理(indexing process)
  - 文本采集(text acquisition)
  - 文本转换(text transformation)：将文档转换为索引项(index term)或特征(feature)。
  - 索引创建(index creation)
- 查询处理(query process)
  - 用户交互(user interaction)
  - 排序(ranking)
  - 评价(evaluation)：一个重要的任务是利用日志数据来记录和分析用户的行为。

## 2.3 组件及其功能
### 2.3.1 文本采集
1. 爬虫(crawler)
2. 信息源(feed):RSS
3. 转换
  - 将HTML,XML,PDF,WORD,PPT转换成统一格式和文档的元数据格式。
  - 保证它们使用统一的编码方案进行转换。
4. 文档数据库

### 2.3.2 文本转换
1. 解析器：处理文本词素(token)序列，词素切分。
2. 停用词去除
3. 词干提取器(stemmer)把同一个词干(stem)得到的派生词进行归类。
4. 超链接抽取和分析
5. 信息抽取：抽取句法特征，如名词短语，需要某种形式的句法分析和词性标注(part-of-speech tagging)。抽取具有指定语义内容的特征，例如，命名实体(named entity)识别器，识别如人名、公司名、日期和地点等。
6. 分类器
  - 给文档分配事先定义好的类别标签。
  - 判别一个文档是否是垃圾文档，以及识别文档中的广告。
  - 聚类用于事先没有定义类别标签的基础上，将相关文档聚集在一起。

### 2.3.3 索引的创建
1. 文档统计：简单汇总和记录词、特征及文档的统计信息。结果存在查找表(lookup table)。
  - 索引项在各文档中出现次数（词及更加复杂的特征）
  - 索引项在文档中出现位置
  - 索引项在一组文档（如标记“体育”）中出现次数
  - 按照词素数量统计文档长度
2. 加权：利用文档统计结果计算权值，并将权值存储在查找表中。如if·idf
3. 倒排(inversion):将文本转换组件传递过来的文档-词信息流转换为词项-文档信息，以便于建立倒排索引。
4. 索引分派：将索引分发给多台计算机。

### 2.3.4 用户交互
1. 查询输入
2. 查询转换：用于在生成好序的文档之前和之后改善初始查询。
  - 文本转换技术:在查询文本上，需要进行词素切分、停用词去除和词干提取。
  - 拼写检查(spell checking)和查询建议(query suggestion):向用户提供初始查询的一些候选查询，这些候选查询可能纠正了拼写错误或是对用户所需信息的更规范描述。
  - 查询扩展(query expansion):对查询进行推荐或增加一些额外的词项，在对文档中词项的出现情况分析的基础上进行。
  - 相关反馈(relevance feedback):一种查询扩展技术，利用用户认为相关的文档中出现的词项对查询进行扩展。
3. 结果输出
  - 生成网页摘要(snippets)
  - 强调(highlighting)文档中重要的词和段落
  - 对输出结果聚类以找到文档相关的类别
  - 将相应广告增加到结果中

### 2.3.5 排序
1. 打分机制
  - $\sum_iq_id_i$ ,qi是查询中第i个词项的权值，di是文档词项的权值。
2. 性能优化：降低系统的响应时间，提高查询吞吐量。
  - term-at-a-time
  - document-at-a-time
  - 安全的(safe)的优化方式与不安全的(unsafe)的优化方式
3. 分布式

### 2.3.6 评价
1. 日志
  - 点击日志(点击数据)
  - 驻留时间(dwell time)
2. 排序分析
3. 性能分析

# 3.信息采集与信息源
## 3.1 确定搜索内容
## 3.2 网络信息爬取
1. 抓取网页
2. 网络爬虫
3. 时新性
4. 面向主题的信息采集
5. 深层网络：那些爬虫很难找到的站点（deep Web，也称hidden Web）
  - 私人站点：没有任何指向它的链接
  - 表单结果
  - 脚本页面（JavaScript，Flash）
6. 网站地图(sitemap)
7. 分布式信息采集

## 3.3 文档和电子邮件采集
## 3.4 文档信息源
pull类型信息源常见RSS。

## 3.5 转换问题
## 3.6 存储文档
## 3.7 重复检测
- 完全重复文档检测：checksumming，含有相同字符当顺序不同，具有相同checksum。
- 考虑字符出现位置：cyclic redundancy check，CRC
- 近似重复检测：指纹（fingerprint），生成指纹过程：
  - 首先对文档进行分词。删除不是词的内容（空格，HTML标签等）。
  - 对于给定n，将这些词组合成n-gram。通常是相互重叠的词序列。
  - 其中的一些n-gram被选择用于表示该文档。
  - 对这些被选择的n-gram进行散列，以提高检索效率，并进一步减少文档表示的大小。
  - 将散列值进行存储。

## 3.8 去除噪声
Finn(2001):在网页中主要内容部分的文本会比网页中附加内容的文本含有更少量的HTML标签。

# 4.文本处理
## 4.1 从词到词项
- 搜索引擎之所以有效的原因，是文本的很多含义通过词语出现和共现的次数获得。
- 理解文本的统计性质是理解检索模型和排序算法的基础。

## 4.2 文本统计
