![cover](https://img9.doubanio.com/view/subject/s/public/s24920254.jpg)

    作者: Tony Russell-Rose / Tyler Tate
    出版社: Morgan Kaufmann
    副标题: The Information Architecture of Discovery
    出版年: 2013-1-2
    页数: 320
    定价: USD 39.95
    装帧: Paperback
    ISBN: 9780123969811

- [豆瓣](https://book.douban.com/subject/11638263/)
- [oreilly](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/)

---

- [1.A Framework for Search and Discovery](#1a-framework-for-search-and-discovery)
  - [1.The User](#1the-user)
    - [Novices and Experts](#novices-and-experts)
      - [Domain expertise versus technical expertise](#domain-expertise-versus-technical-expertise)
      - [Double novices orienteer](#double-novices-orienteer)
      - [Double experts teleport](#double-experts-teleport)
      - [The in-betweeners](#the-in-betweeners)
      - [Serial and holistic thinkers](#serial-and-holistic-thinkers)
      - [The rod-and-frame test](#the-rod-and-frame-test)
      - [Serialists: brick-by-brick craftsmen](#serialists-brick-by-brick-craftsmen)
      - [Holists: big-picture visionaries](#holists-big-picture-visionaries)
      - [The performance gap](#the-performance-gap)
      - [Designing for learnability](#designing-for-learnability)
    - [Verbal and Visual Learners](#verbal-and-visual-learners)
      - [From five senses to three modalities](#from-five-senses-to-three-modalities)
      - [Dual coding theory](#dual-coding-theory)
      - [Designing with overviews and previews](#designing-with-overviews-and-previews)
  - [2.Information Seeking](#2information-seeking)
    - [Models of Information Seeking](#models-of-information-seeking)
      - [The classic model](#the-classic-model)
      - [The standard model](#the-standard-model)
      - [The cognitive model](#the-cognitive-model)
      - [The dynamic model](#the-dynamic-model)
      - [The information journey model](#the-information-journey-model)
    - [Information Foraging](#information-foraging)
      - [A biological foundation](#a-biological-foundation)
      - [Man the informavore](#man-the-informavore)
      - [Information foraging theory](#information-foraging-theory)
      - [Designing with information scent](#designing-with-information-scent)
        - [Descriptive titles](#descriptive-titles)
        - [Hit highlighting](#hit-highlighting)
        - [Clear labeling](#clear-labeling)
    - [Sensemaking](#sensemaking)
      - [Human memory](#human-memory)
      - [Four stages of the sensemaking process](#four-stages-of-the-sensemaking-process)
      - [From internal to external schemas](#from-internal-to-external-schemas)
      - [Designing for sensemaking](#designing-for-sensemaking)
        - [The shoebox](#the-shoebox)
        - [The evidence file](#the-evidence-file)
        - [The schema](#the-schema)
    - [Stages of Information Seeking](#stages-of-information-seeking)
      - [The six-stage funnel](#the-six-stage-funnel)
      - [Designing for the journey](#designing-for-the-journey)
        - [Open-ended exploration](#open-ended-exploration)
        - [Information management](#information-management)
        - [Monitoring](#monitoring)
  - [3.Context](#3context)
    - [A Framework for Context](#a-framework-for-context)
    - [A Context-Based Model of Search](#a-context-based-model-of-search)
      - [Four layers of context](#four-layers-of-context)
        - [The information retrieval layer](#the-information-retrieval-layer)
        - [The information seeking layer](#the-information-seeking-layer)
        - [The work task layer](#the-work-task-layer)
        - [The cultural layer](#the-cultural-layer)
      - [Designing across layers](#designing-across-layers)
    - [Physical Context](#physical-context)
      - [Here and now](#here-and-now)
        - [Spatial context](#spatial-context)
        - [Temporal filters](#temporal-filters)
      - [Push versus pull](#push-versus-pull)
    - [The Information Landscape](#the-information-landscape)
      - [Content frameworks](#content-frameworks)
      - [Unstructured information](#unstructured-information)
      - [Aggregate information](#aggregate-information)
  - [4.Modes of Search and Discovery](#4modes-of-search-and-discovery)
    - [Search Modes and Frameworks](#search-modes-and-frameworks)
    - [Designing for Search Modes](#designing-for-search-modes)
      - [Lookup: verify](#lookup-verify)
      - [Learn: explore](#learn-explore)
      - [Investigate: analyze](#investigate-analyze)
    - [Mode Chains and Patterns](#mode-chains-and-patterns)
    - [Designing for Mode Chains](#designing-for-mode-chains)
- [2.Design Solutions](#2design-solutions)
  - [5.Formulating the Query](#5formulating-the-query)
    - [Entering the Query](#entering-the-query)
      - [The search box](#the-search-box)
      - [Scoped search](#scoped-search)
      - [Search within](#search-within)
      - [Advanced search](#advanced-search)
      - [Beyond keywords](#beyond-keywords)
        - [Natural language](#natural-language)
        - [Nontext queries](#nontext-queries)
    - [Refining the Query](#refining-the-query)

# 1.A Framework for Search and Discovery
The most fundamental step is to recognize that the opinions are themselves based on a set of **assumptions**—in particular, assumptions about **who** is doing the searching, **what** they are trying to achieve and under **what circumstances**, and **how** they are going about it. Each of these assumptions corresponds to a separate `dimension` by which we can define the search experience.

**The Dimensions of Search User Experience**

The first of these dimensions is the `type of user`, in particular his or her level of **knowledge and expertise**.
For example, consider the users of an online retail store: are they knowledgeable enthusiasts or novice shoppers? Likewise, for an electronic component supplier: are the users expert engineers or purchasing agents with limited domain knowledge?

Once we understand the user, we can move on to the second dimension: his or her `goal`. This goal can vary from simple fact checking to more complex explorations and analyses. For example, are users searching for a specific item such as the latest Harry Potter book? Or are they looking to choose from a broader range of possibilities, such as finding shoes to match a business suit? Or are they unsure of what they are looking for in the first place, knowing only that they would like to find a suitable gift?

Knowing the users and their goals, we can now consider the third dimension: the `context`. Context includes a range of influences, from the physical to the intangible. For example, is the user at the workplace, where the task and the organizational setting dominate? Or is the user at home, where `social context` might become more important? Perhaps he or she is using a mobile device while travelling, during which `physical context` shapes the search experience.

Finally, based on our understanding of the users, their task and the wider context, we can consider the fourth dimension: their `search mode`. Search isn’t just about finding things—on the contrary, most finding tasks are but a small part of a much larger overall task. Consequently, our focus must be on understanding the complete task life cycle and helping users complete their overall information goals. This includes activities such as comparing, exploring, evaluating, analyzing, and much more.

## 1.The User
### Novices and Experts
Expertise plays a significant role in how people seek information. Understanding the differences between novices and experts will enable us to design better search experiences for everyone. But first, it’s worth distinguishing between two dimensions of expertise.

#### Domain expertise versus technical expertise
`Domain expertise` defines one’s familiarity with a given subject matter; a professional photographer, for instance, has substantial domain expertise in the field of photography. `Technical expertise`, on the other hand, indicates one’s proficiency at using computers, the Internet, search engines, and the like.

In combination, the domain and technical dimensions of expertise describe four types of users (Figure 1.1):

- Double experts
- Domain expert/technical novices
- Domain novice/technical experts
- Double novices

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-01-9780123969811.jpg)

Figure 1.1 Two dimensions of expertise: domain and technical.

#### Double novices orienteer
Double novices share three main characteristics (Hölscher and Strube, 2000):

1. **Frequent query reformulation**. Novices perform more queries than experts but look at fewer pages. Although they frequently reformulate their query, double novices often make only small, inconsequential changes to their search phrase.
2. **Going back**. When novices do click on a search result, they are much more likely than experts to then navigate back to the search page. With a fear of venturing too far from safety, double novices practice a hub-and-spoke pattern of information seeking with the search page firmly at the center.
3. **More time spent**. The many queries and frequent backward-oriented behavior of double novices causes them to spend more time on a given search task than would an expert.

Because novices frequently refine their original query but often don’t make radical enough changes, showing a list of related searches (as demonstrated by Foodily in Figure 1.2) can help users make more successful query reformulations. In addition, breadcrumbs accomplish the dual purpose of communicating the user’s current location, while also providing a path to go back (Figure 1.3).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-02-9780123969811.jpg)

Figure 1.2 Foodily’s iPhone application places related searches at the bottom of the page, after the search results.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-03-9780123969811.jpg)

Figure 1.3 The breadcrumbs on Zappos.com indicate which filters the user has applied and provide the means to remove them.

#### Double experts teleport
Double experts are characterized by three tendencies (Hölscher and Strube, 2000):

1. **More pages examined**. Double experts click on more search results than do novices.
2. **Going deeper**. Double novices tend to retreat from the pages they examine; double experts rarely go back. Instead, experts follow links from one page to the next, progressing deeper into the information space with each step.
3. **Less time spent**. Double experts are time-efficient in their search tasks. Not only do they reformulate their queries less often, but they can also determine the relevancy of a given page more rapidly than novices.

Expert-friendly search user interfaces should support advanced syntax and filtering to help users quickly narrow their search. Although the Boolean operators AND, OR, and NOT are certainly worth supporting, Wolfram Alpha (shown in Figure 1.4) goes a step further and allows users to input domain-specific terminology and retrieve computed answers. Similarly, a faceted search interface for filtering by format, selecting ranges, or excluding certain categories—such as Getty’s Moodstream, shown in Figure 1.5—can help users pinpoint content that’s relevant to their information needs.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-04-9780123969811.jpg)

Figure 1.4 Wolfram Alpha is designed to return computed answers using advanced syntax and domain-specific terminology.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-05-9780123969811.jpg)

Figure 1.5 Getty Image’s Moodstream lets users search for stock photos using slider controls.

#### The in-betweeners
Domain expert/technical novices, for instance, use their knowledge to enter effective queries and quickly evaluate pages, but they lack the technical confidence to explore unknown territory (Jenkins et al., 2003). Their traits include:

1. **Advanced terminology**. Domain experts are able to rely on their extensive vocabulary to construct more topical queries than are domain novices.
2. **Effective evaluation**. Similarly, high domain knowledge makes the process of evaluating a page more meaningful and timely.
3. **Going back**. A lack of technical expertise, however, contributes to a sense of disorientation, preventing users from venturing too far away from the search page.

Domain novice/technical experts, on the other hand, brim with confidence, but have trouble discerning relevant content (Hölscher and Strube, 2000). They are characterized by:

1. **Advanced formatting**. Technical experts are much more likely to use query formatting techniques—such as double quotes and Boolean operators—than are technical novices.
2. **Confident exploration**. Despite their lack of domain expertise, technical experts exude confidence and never worry about becoming disoriented.
3. **Difficulty with evaluation**. Technical expertise doesn’t compensate for a lack of domain knowledge when it comes to evaluating the relevance of a page.

#### Serial and holistic thinkers
Psychologists call these `cognitive styles`—the stable attitudes, preferences, and habits that determine how an individual processes and represents information. We’ll begin by looking at the `serial-holistic style` of information processing.

#### The rod-and-frame test
Here it is: draw a vertical line inside the rectangle.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-06-9780123969811.jpg)

Figure 1.6 Complete a simplified version of the rod-and-frame test by drawing a vertical line in the rectangle.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-07-9780123969811.jpg)

Figure 1.7 Serialists complete the rod-and-frame test by drawing the line aligned with the edges of the rectangle (left). Holists, on the other hand, draw the line along the global north–south axis (right).

#### Serialists: brick-by-brick craftsmen
Like skilled craftsmen, serialists are highly attuned to the details. When learning, serialists tend to drill down to narrow subtopics and follow a logical progression from one to the next. Despite being skilled at analyzing the component parts (Figure 1.8), serialists have greater difficulty combining the parts into a whole (Kim, 2001).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-08-9780123969811.jpg)

Figure 1.8 Serialists concentrate on the individual parts rather than the whole.

#### Holists: big-picture visionaries
Holists are visionaries with a bird’s-eye view (Figure 1.9). Operating with an intrinsic motivation that is independent of their surroundings, holists flourish in flexible environments where they are free to pursue their own interests at the pace of their choice. When approaching a topic, they immediately set out to comprehend the big picture, giving holists a more balanced view and helping them put situations into context. However, holists are also prone to oversimplification, sometimes glossing over important details (Ford et al., 2002).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-09-9780123969811.jpg)

Figure 1.9 Holists focus on the cohesive whole rather than on component parts.

#### The performance gap
Holists are more efficient at satisfying their information needs. Serialists, by comparison, find it more difficult to discern the relevance of information and consequently spend more time searching for the same answers.

Although there is a wide gap in performance between serialists and holists who are `technical novices`, the gap all but disappears between the two cognitive styles when `technical expertise` is high. In other words, user interfaces can become more effective by helping serialist novices—or all novices, for that matter—increase their level of technical expertise.

#### Designing for learnability
`Learnability`—the ease with which users gain awareness of available software functions and comprehend how to act on them—can be accomplished using `contextual instructions`, `immersive overlays`, and `subtle visual design`.

A simple contextual instruction, for example, can be achieved by adding descriptive placeholder text to the search box (Figure 1.10). The text can inform users about the type of query that the system expects—whether it’s the name of a restaurant, an area of a city, or a postal code.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-10-9780123969811.jpg)

Figure 1.10 Toptable’s iPhone application combines the use of placeholder text and a three-option segmented control to clearly indicate the type of input that the application expects from the user.

`Contextual popovers`, like the ones used by Foodily in Figure 1.11, can augment a well-designed interface and reduce the guesswork required by the user. `Immersive, full-screen overlays` —such as the welcome screen to the TapTu iPad app shown in Figure 1.12—can serve a similar purpose. Caution is required in both situations, however; providing tips for new users must be balanced with concern for more experienced users (both Foodily and TapTu, for instance, show the “getting started” advice only on a user’s first visit).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-11-9780123969811.jpg)

Figure 1.11 Foodily, a recipe search site, uses small popovers to introduce first-time users to a few of the features unique to Foodily’s website.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-12-9780123969811.jpg)

Figure 1.12 TapTu, a news-reading application, uses an overlay to provide a tutorial for new users.

A more nuanced method for enhancing learnability is to use subtle animation and tactile textures to suggest gestures, hint at off-screen content, and indicate which elements on the screen are interactive. When a user first views a list of search results using Airbnb’s iPhone application (shown in Figure 1.13), for instance, an animation reveals a star behind each result before quickly disappearing, hinting that a swipe from left to right will “favorite” that particular item. Such tactics are especially useful on mobile devices where screen space is scarce.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-13-9780123969811.jpg)

Figure 1.13 On the first use, Airbnb’s iPhone application reveals a star behind each search result before quickly sliding away, training users to use a left-to-right gesture to “favorite” a result.

### Verbal and Visual Learners
![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-14-9780123969811.jpg)

Figure 1.14 Two dimensions of cognitive style: serial–holistic and verbal–visual.

#### From five senses to three modalities
We experience the world through five senses, distilled by psychologists into three “sensory modalities” relevant to learning: verbal, visual, and kinesthetic (Denig, 2004). Though everyone learns through all three modes, we each favor one over the others, resulting in three different styles of learning:

1. `Verbal` learners absorb written and spoken information more readily than visual concepts. Because most learning is either text-based (reading a book, searching online) or auditory (a classroom lecture or personal conversation), verbal learners have ready access to content in their preferred medium.
2. `Visual` learners, on the other hand, digest information from charts, diagrams, timelines, maps, and other concrete images more easily than from the written or spoken word. Visual learners have less access to appropriate content than their verbal counterparts.
3. `Kinesthetic` learners enjoy hands-on activities involving movement, from dancing to woodwork. Although kinesthetic learning is minimally involved in desktop computing, it plays a much more significant role in gestural and touch-based interfaces.

#### Dual coding theory
In the 1970s, psychologist Allan Paivio made an important observation: people learn best when information is presented in two modalities at the same time, which is now known as the `Dual-Coding Theory`. 

#### Designing with overviews and previews
Although dual coding theory has significant implications for website content, it’s also important for the search experience. In particular, `visual overviews` and `previews` can augment text-based lists to both describe the result set as a whole, as well as the individual result itself (Greene et al., 2000).

Mapumental, for example, distills transit times, house prices, and “scenicness” ratings into a composite map overlay that helps its users choose where to live. Crunching these numbers oneself would be an enormous task, yet the map in Figure 1.15 instantly shows which areas of London are no farther than a 45-minute commute from Waterloo Station, have an average house price of less than £400,000, and score at least 2 out of 10 in scenicness.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-15-9780123969811.jpg)

Figure 1.15 Mapumental visualizes a synthesis of transit times, house prices, and “scenicness” ratings to help users choose where to live.

Google Finance’s stock screener, for example (shown in Figure 1.16), efficiently combines dual sliders with a histogram to provide contextual feedback for users searching for companies by financial criteria.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-16-9780123969811.jpg)

Figure 1.16 Histograms, such as these from Google Finance’s stock screener, instantly convey the distribution of results.

While `overviews` provide a visual depiction of the result set as a whole, `previews` help the user examine an individual result in greater detail—augmenting verbal information with a visual component to help the user make better relevance judgments. In some cases—such as ecommerce—visual thumbnails can even be more important than the text (Figure 1.17).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-17-9780123969811.jpg)

Figure 1.17 For many ecommerce websites, such as NorthFace.com, visual thumbnails are more important than textual descriptions.

Larger previews, rather than help the user quickly skim the results, gives the user a chance to verify the relevance of a result before committing to viewing the full item. Apple’s Spotlight search, for example (shown in Figure 1.18), previews a document as the user hovers over its title, reducing the inconvenience of opening a new document only to discover that it’s irrelevant.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-18-9780123969811.jpg)

Figure 1.18 Apple’s Spotlight search shows document previews as the user interacts with the search results.

## 2.Information Seeking
Mankind is an endless pursuer of knowledge.

We bridge this knowledge gap by asking those around us for advice, turning to books and encyclopedias, and, increasingly, searching the Internet. This journey between need and fulfillment is called `information seeking`.

### Models of Information Seeking
#### The classic model
The classic model is one of the first models of information retrieval, widely used in information science research for over 30 years (Robertson, 1977).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-01-9780123969811.jpg)

Figure 2.1 The classic model of information retrieval.

#### The standard model
In contrast with the classic model, the standard model places greater emphasis on the user. It portrays information seeking as a type of problem solving (Marchionini, 1995) involving a cycle of four activities (Sutcliffe & Ennis, 1998):

1. Identifying the problem
2. Articulating the information need
3. Formulating the query
4. Evaluating the results

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-02-9780123969811.jpg)

Figure 2.2 The standard model of the search process.

#### The cognitive model
Like the standard model, Don Norman’s cognitive model of task performance (shown in Figure 2.3) also views search as a form of problem solving driven by an explicit user goal (Norman, 1988). But in this case, users apply a mental model—an internal representation of the problem situation and its context—to develop a plan of action to achieve that goal. These actions lead to changes in the external world that are evaluated to determine whether the goal has been achieved.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-03-9780123969811.jpg)

Figure 2.3 Don Norman’s cognitive model of task performance.

A key insight of Norman’s model over the previous two is that it recognizes the importance of domain knowledge (as discussed in Chapter 1): the greater the users’ knowledge, the more likely they are to articulate effective queries and accurately determine the relevance of results.

#### The dynamic model
Both the standard and cognitive models share an underlying assumption that the user’s information need remains unchanged throughout a given session. They view the process of information seeking as one of iteratively refining a given query until the ideal set of results is found. However, numerous studies have found that users’ information needs evolve as they interact with information and that they formulate new goals as they acquire domain knowledge. Far from being static, search is an interactive, iterative process in which the answer can change the question. As Peter Morville puts it, “what we find changes what we seek” (Morville, 2009).

Consequently, we need a model that accounts for changes in users’ information needs as they learn and respond to the information they encounter. The dynamic model proposed by Marcia Bates (1989) accomplishes just that (Figure 2.4).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-04-9780123969811.jpg)

Figure 2.4 Marcia Bates’ dynamic model.

#### The information journey model
Ann Blandford and Simon Attfield (2010) have further explored the unfolding journey of information seeking. Like the dynamic model, their information journey model (shown in Figure 2.5) has been derived from empirical studies of user behavior. The main activities in their framework are:

1. Recognizing an information need
2. Acquiring information
3. Interpreting and validating the information
4. Using the information

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-05-9780123969811.jpg)

Figure 2.5 The information journey model.

These information encounters are what we commonly label serendipity. The information journey model, with its multiple entry points, acknowledges `serendipity` as part of the information seeking experience.

### Information Foraging
`Information foraging`, an instinct closely related to that found in animals hunting for food, interacts with `sensemaking`, the cognitive process for deriving meaning from new information. Together, information foraging and sensemaking form a feedback loop (Pirolli & Card, 2005) that underpins the information seeking process.

#### A biological foundation
Biologists in the 1960s observed that animals often eat a particular type of food in one environment but ignore the same food in other places. Ecologists Robert MacArthur and Eric Pianka set out to discover how animals decide what to eat. Their research, and their accompanying `optimal foraging theory` (MacArthur & Pianka, 1966), provides a foundation for understanding our own behavior when searching for information.

According to optimal foraging theory, animals live in environments consisting of many “patches,” each with a unique blend of potential food sources.

This principle of diminishing returns is known in ecology as the `marginal value theorem` (Charnov, 1976). The theory asserts that animals perform a cost/benefit analysis on staying in the current patch versus traveling to a new one—considering both current and potential food supplies as well as the transit time between the two patches (Figure 2.6).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-06-9780123969811.jpg)

Figure 2.6 Charnov’s marginal value theorem states that a forager should leave a given patch when the rate of gain within that patch drops below the rate of gain that could be achieved by traveling to a new patch.

#### Man the informavore
George Miller portrayed our species as `informavores`: creatures hungry for information (Miller, 1983). But just like the bear must be selective in its diet (digging all day for a few measly ants would hardly be worthwhile), so must informavores carefully navigate the glut of information in our modern environment. Herbert Simon spoke of this perilous balance in 1971:

>What information consumes is rather obvious: it consumes the attention of its recipients. Hence a wealth of information creates a poverty of attention, and a need to allocate that attention efficiently among the over-abundance of information sources that might consume it. (p. 40)

Although information is what we seek, our limited supply of attention forces us to make a tradeoff between comprehensiveness and timeliness. Simon coined the term satisficing—a combination of the words “satisfy” and “suffice”—to describe this pragmatic decision-making strategy that pervades human behavior (Simon, 1956).

#### Information foraging theory
Peter Pirolli and Stuart Card, researchers at the Palo Alto Research Center (PARC), began applying the principles of optimal foraging theory to information seeking in the early 1990s, establishing a new framework called `information foraging theory` (Pirolli & Card, 1999). Pirolli and Card drew a connection between users moving from one website to the next and animals traveling from patch to patch. They observed that users, in an effort to satisfice, heavily rely on certain cues known as `information scent` to guide them toward their destination.

As users traverse the Web, they encounter information scent when `“trigger words”`—terms they perceive as meaningful to their task—are used in the text of a hyperlink, as words in a heading, or in a search result’s description. The more trigger words that are present, the stronger the information scent (Spool et al., 2004). When information scent grows stronger from page to page, users are confident that they’re headed in the right direction. But when it’s weak, they may be uncertain about what to do or even give up.

In addition to information scent, Pirolli and Card’s research also helps explain `information snacking` (Nielsen, 2003). According to the marginal value theorem, the amount of time a user spends on a given website is proportional to the travel time between sites. As between-patch time decreases—thanks to Google and fast Internet connections—users spend less time on any one site. The result is that information seeking has become less of a sit-down banquet and more of an opportunistic buffet.

#### Designing with information scent
##### Descriptive titles
Before clicking on a search result—or even reading its two-line description—the title must first be deemed relevant. Obvious though it is, the presentation of clear, descriptive titles is the surest method for providing strong information scent when displaying search results.

Jared Spool found that reasonably long titles tend to work better than shorter ones, with links of 7 to 12 words being most likely to lead to a successful outcome (Figure 2.7).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-07-9780123969811.jpg)

Figure 2.7 Jared Spool found that 7- to 12-word links yield the greatest likelihood of a user finding what he or she is looking for.

##### Hit highlighting
When the user performs a query, he or she inputs the most important terms to his or her search—that is, the query’s `trigger words`. Hit highlighting (Figure 2.8) is the technique of emphasizing the words included in the query wherever they appear on the search results page. Using a bold font weight helps to draw the user’s eye to the trigger words, increasing information scent.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-08-9780123969811.jpg)

Figure 2.8 Bing uses a bold font weight to highlight the user’s query terms whenever they appear in the search result list, for both exact phrase matches (e.g., “artificial intelligence”) and partial matches (e.g., “intelligence”).

##### Clear labeling
When searching through online content, for instance, the user might be looking for business news and wish to skip over sport and entertainment articles (Figure 2.9). Clearly identifying which category a given result belongs to can help users ignore unwanted documents and focus on their genre of choice (Drori, 2002).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-09-9780123969811.jpg)

Figure 2.9 The BBC labels each news story with a category, such as “Europe” or “Business.”

### Sensemaking
`Sensemaking`—a concept developed in the information science field by Brenda Dervin (1983) and in human–computer interaction by PARC researchers Daniel Russell and colleagues—describes the process through which people assimilate new knowledge into their existing understanding (Russell et al., 1993). Just as the study of information foraging behavior has led to techniques for designing more fluid search experiences, so can an appreciation of how people make sense of information help us design tools that facilitate comprehension, analysis, and insight.

#### Human memory
Most relevant for our purpose, however, is long-term `semantic` memory, which is responsible for keeping track of our ever-growing conceptual knowledge (Tulving, 1985). Semantic memory organizes knowledge into a schema of interconnected nodes that our minds can manipulate and explore at will (Miller, 1987), a simplistic visualization of which can be represented by mind map diagrams such as the one in Figure 2.10.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-10-9780123969811.jpg)

Figure 2.10 This mind map created on MindMeister.com visualizes one person’s understanding of western philosophy.

This internal semantic schema is constantly in flux. New information may require our semantic memory to add new nodes to the existing schema, reorganize the links between nodes, or discard concepts that are no longer pertinent. This is the realm of **sensemaking: growing, rearranging, and pruning the semantic tree of knowledge**.

#### Four stages of the sensemaking process
1. Search
2. Extract
3. Encode
4. Analyze

#### From internal to external schemas
Thus far, we’ve treated the semantic schema as the internal model of an individual’s knowledge. However, the finite capacity of the human mind ensures that one’s own understanding is only a subset of reality. In the same way that a map is a compact representation of a much larger landscape, so our internal semantic schema is a simplified sketch of a much broader body of knowledge.

Sophisticated information tasks demand that one’s `internal` semantic model be disseminated into an `external` schema. External schemas can not only store a greater amount of information than an internal schema, but can also serve as a conduit for collaboration.

#### Designing for sensemaking
##### The shoebox
The first step in many investigations is to gather potentially relevant documents into a single collection—what could be coined the shoebox (a term that recollects putting something away for later). At this stage, the analyst isn’t concerned with a close examination of each document; the top priority is to populate the shoebox as quickly as possible with anything that might be relevant to the investigation. The analyst heavily relies on information scent to make rapid judgments about which documents should and should not be included. To support this behavior, the user interface should enable the analyst to add documents to the shoebox as rapidly as possible. For instance a text link, checkbox, or icon (Figure 2.11) could be provided for quickly saving a given search result.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-11-9780123969811.jpg)

Figure 2.11 Airbnb.com places a star icon next to each search result. Clicking on the star saves that result to the user’s “favorites list.”

##### The evidence file
Once the shoebox has been populated with potentially relevant documents, the analyst often then begins a more thorough examination of the curated collection. This time around, the analyst spends significantly more time scrutinizing the text and images when looking for possible leads. When the analyst spots a striking sentence or meaningful image, he or she extracts that snippet and saves it to a more cogent collection of relevant information: the evidence file.

A simple example of an evidence file is Mendeley, a tool that helps academics manage their research. Mendeley provides a special bookmark that users can add to their web browsers (Figure 2.12). When clicked, a popup window appears and prompts the user to save a title, keywords, tags, and meaningful notes extracted from the current page.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-12-9780123969811.jpg)

Figure 2.12 Mendeley’s document import tool.

##### The schema
The external schema provides an even bigger picture of how the extracted evidence fits together. It may be constructed of the people, places, and events surrounding a crime or the causes and symptoms of a disease (Figure 2.13). Also known as an ontology—a specification of a shared conceptualization—the external schema enables analysts to continually explore, gain insights from, and test hypotheses against the model as it is constructed.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-13-9780123969811.jpg)

Figure 2.13 The “conditions and diseases” node of a much larger external semantic schema on the NHS Evidence website.

### Stages of Information Seeking
#### The six-stage funnel
Carol Kuhlthau, a professor at Rutgers University, performed a series of studies during the 1980s to better understand how people seek information to satisfy long-term goals (Kuhlthau, 1991). Kuhlthau identified distinct phases in what she called the `information search process` but is best described as stages of `information seeking` (Figure 2.14). She observed both the tasks and emotions unique to each of six phases:

1. Initiation
2. Selection
3. Exploration
4. Formulation
5. Collection
6. Action

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-14-9780123969811.jpg)

Figure 2.14 Kuhlthau’s six stages of information seeking can be represented as a funnel that begins open-ended and ends with a resolution.

#### Designing for the journey
##### Open-ended exploration
Whether the task is looking for a place to live, finding the perfect car, or planning a vacation, it’s unlikely that the user knows exactly which house is best, what car is ideal, or precisely where to go on holiday at the outset. Yet these are often the first questions that real estate, automotive, and travel sites ask us (Figure 2.15).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-15-9780123969811.jpg)

Figure 2.15 Autotrader.co.uk asks the user to specify an exact make and model of car up front.

In order to engage users earlier in their journey, we must help them explore (Marchionini, 2006). Flexible filtering controls can facilitate browsing without the need for an initial query, helping the user survey the information landscape and potentially make serendipitous discoveries along the way. Although automotive sites AutoTrader and Motors.co.uk both allow users to choose specific makes and models, the latter (Figure 2.16) also caters to those who haven’t yet formulated an exact specification, allowing them to filter by body style, color, number of doors, number of seats, and many other factors.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-16-9780123969811.jpg)

Figure 2.16 Motors.co.uk provides flexible filtering options, making it easy for users to look for cars even before deciding on a particular make and model.

##### Information management
Equipping users to bookmark, categorize, and annotate findings can greatly streamline the long-term information seeking process.

Bookmarking can help users refind items of interest at a later date. What’s more, grouping bookmarks into meaningful sets—like placing recipes into “meal plans” on Foodily (Figure 2.17)—can help users organize large collections of information. Ratings and annotations—such as the personal notes and one- to five-star rankings that can be added to saved properties on Globrix (Figure 2.18)—can further extend the user’s memory by making it easier to compare and differentiate saved items.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-17-9780123969811.jpg)

Figure 2.17 Foodily, a recipe search engine, allows users to save their favorite recipes and organize them into meal plans.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-18-9780123969811.jpg)

Figure 2.18 Property search site Globrix allows users to assign a rating and write notes on each property that they’ve bookmarked.

##### Monitoring
Applications can facilitate monitoring in two ways: on demand or automatically. Enabling the user to save a search query along with any applied filters provides a means for returning to that query `on demand` at a later date. Often, however, users may prefer to be `automatically notified` by email when a new match to their criteria appears, reducing the need to continually check back (eBay, pictured in Figure 2.19, provides both).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-19-9780123969811.jpg)

Figure 2.19 eBay allows users to save searches and, by checking a box, to be notified by email when new items are added.

## 3.Context
### A Framework for Context
Context can also be defined in terms of its constituent parts. Myrhaug and Goker (2003), for instance, propose a framework of five key components:

- Task. Any goals, tasks, actions or activities associated with what the user is doing.
- Spatiotemporal. Attributes relating to the current time, location, direction, and so on.
- Personal. The user’s physiological context, mental state, preferences, and so on.
- Social. The user’s role, status, and relationships with other individuals.
- Environmental. Factors including temperature, light, humidity, and, on a slightly different note, the information resources accessed by the user.

Frameworks such as this help us understand the role of context in search and form the basis for a principled approach to design. As Lieberman and Selker (2000) put it:

>A considerable portion of what we call…good design in human computer interaction actually amounts to being sensitive to the context in which the artifacts are used. Doing the “right thing” entails that it be right given the user’s current context. (p. 617)

### A Context-Based Model of Search
#### Four layers of context
Figure 3.1 presents an example of this influence based on the work of Jarvelin and Ingwersen (2004). This model represents the task context as a set of layers that start at the micro level (information retrieval) and extend outward to the macro level (culture).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-01-9780123969811.jpg)

Figure 3.1 A context-based model of search.

##### The information retrieval layer
At the most granular level of the model is information retrieval. This layer is typified by simple, focused tasks such as finding a specific document related to a keyword query.

These tasks are often referred to as `known item searches`. They may involve a number of iterations but are usually confined to a single session.

The success of tasks at this level is commonly evaluated using system-oriented metrics such as precision and recall.

##### The information seeking layer
At the next level is information seeking. This layer is associated with broader, more complex tasks that attempt to satisfy an information need or problem (Marchionini, 1995).

In this context, users need to exercise judgment regarding which strategies to adopt, such as where, how, and when to look for information (Wilson et al., 2010).

##### The work task layer
The information need that precipitates information seeking is itself motivated by a further level: the `work task`. This layer is characterized by higher-level tasks that are created when the user recognizes an information need based on either an organizational need or a personal motive (Marchionini, 1995).

Work tasks situated in an organizational setting are likely to reflect local resources, constraints, and working practices (Wilson et al., 2010). This list can include which resources are available to satisfy a given information need, such as reference materials, libraries, human experts, and others. Evaluation at this level focuses on assessing performance of the overall task.

##### The cultural layer
This level influences not only the overall task requirements but also the collective importance attached to meeting them.

#### Designing across layers
Unfortunately, tasks at this level are often poorly supported by online retailers, and a query for “home entertainment” returns an opaque list of product categories that relies on the user understanding the terminology and knowing which category to select (Figure 3.2).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-02-9780123969811.jpg)

Figure 3.2 Limited support for the work task level at Comet.

But behind the tab labeled “Videos and Advice” lies a resource (pluggedin.co.uk) that is much more appropriate for this level of task. Instead of product categories, a query for “home entertainment” here returns content much better suited to the immediate goal (Figure 3.3). This content includes tutorials in the form of buyer’s guides and how-to guides alongside product reviews and user-generated content from specialist forums. In contrast to the product category listing seen previously, this material provides far greater support for activities associated with the work task level, such as exploration and learning. In addition, it supports discovery of latent needs through the provision of aspirational articles and expert reviews.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-03-9780123969811.jpg)

Figure 3.3 Support for the work task level at pluggedin.co.uk.

Amazon, for example, supports iterative information seeking via a personalized history panel that includes recent searches and recently viewed items (Figure 3.4). This information is augmented by a facility for users to create, organize, and share their own lists.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-04-9780123969811.jpg)

Figure 3.4 Support for the information seeking level at Amazon.

As the user gets a clearer idea of his or her needs and identifies suitable products, he or she may wish to verify the price and quality of these particular items on independent sites. In this context, the focus shifts from information seeking to a set of specific information retrieval subtasks. This is the level that traditionally has been best supported by online retailers. One notable example of design support for information retrieval can be found at Samsung.com (Figure 3.5), which provides a particularly immersive style of instant results and autocomplete.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-05-9780123969811.jpg)

Figure 3.5 Support for the information retrieval level at Samsung.com.

### Physical Context
#### Here and now
Mobile user needs are driven by the spatiotemporal context: they seek results that are not just relevant to their immediate information need (i.e., topically relevant) but also timely and relevant to their physical location (Goker et al., 2004). These influences, coupled with an increased emphasis on precision over recall, suggest an approach in which these factors are combined to deliver the most contextually relevant results (Figure 3.6).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-06-9780123969811.jpg)

Figure 3.6 Topical, spatial, and temporal filters can be combined to increase the relevance of search results.

##### Spatial context
Spatial context can be modeled in a number of ways. One of the simplest approaches is to equate relevance with physical distance; that is, the closer the spatial footprint of a given item, the more relevant it is (Mountain and MacFarlane, 2007). This approach is offered by many directory services such as Yelp (Figure 3.7).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-07-9780123969811.jpg)

Figure 3.7 Physical distance as a measure of relevance.

Alternatively, spatial relevance could be based on physical accessibility, that is, the amount of time it takes to reach a particular location.

Moreover, spatial context of mobile users is rarely static; often the user is in transit during the interaction itself. In this case, it may be more appropriate to consider the user’s current trajectory and determine relevance based on the user’s predicted location at any point in time.

##### Temporal filters
Temporal context can be also modeled in a number of ways. One of the most intuitive approaches is to equate relevance with “freshness”; This approach could be combined with the spatial footprint to provide a feed of breaking news specific to the user’s current locality (Figure 3.8).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-08-9780123969811.jpg)

Figure 3.8 The Associated Press combines temporal relevance with spatial relevance.

Some types of information have a predictable schedule associated with them, such as the timetables for public transport or the opening hours for shops and services. There is little value in finding restaurants that are currently closed or trains that are no longer running. In order to utilize this type of context, it is necessary to filter results according to the time when the user wishes to travel or partake of the particular service.

#### Push versus pull
Information doesn’t always have to be `pulled` by users in this way. Given knowledge of their preferences, it is possible to `push` information to users whenever it becomes relevant to their physical context. For example, Foursquare, a location-based social network for mobile users, provides real-time push notifications when friends “check in” at various locations (Figure 3.9).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-09-9780123969811.jpg)

Figure 3.9 Foursquare provides push notification of location-based updates.

Location-based advertising is the ultimate example: from a marketing perspective, it offers almost unlimited potential for presenting contextually relevant promotions to consumers based on their current location. However, this type of service will be tolerated only if the relevance and value of the information outweighs the cost of the intrusion and the associated lack of privacy (Figure 3.10).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-10-9780123969811.jpg)

Figure 3.10 Location-based promotions employed by Groupon.

### The Information Landscape
#### Content frameworks
Cool and Belkin (2002) suggest an approach in which content is defined by three dimensions:

- Level: information, meta-information
- Medium: image, written text, speech, and so on
- Quantity: one object, set of objects, database of objects

#### Unstructured information
At the simplest level, this experience means **making the unstructured content searchable alongside the product records they support and presenting the results in a coordinated manner**. By selecting the appropriate tab, the user can pivot to a “Reviews View” that shows those same products displayed in list view with their associated customer reviews and ratings (Figure 3.11).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-11-9780123969811.jpg)

Figure 3.11 Moosejaw allows browsing of both product results and reviews.

A search for “fridge freezers” on electronics retailer Comet, for instance, returns a set of 273 products with 79 associated reviews. But this time, **the user can filter the product results using the review metadata**. For example, he or she can choose to see just those products that received five-star reviews from 25- to 34-year-old males in a “small family” (Figure 3.12).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-12-9780123969811.jpg)

Figure 3.12 Comet allows users to navigate products by review rating and reviewer profile.

**Unstructured content can lend itself to a more visual treatment, ranging from simple keyword tag clouds to more sophisticated charts and graphs**. Newssift (now closed) extracted named entities such as people, places, and organizations (shown in the middle three columns in Figure 3.13) and used various text analysis techniques to measure sentiment of the content, which it rendered using the pie chart on the left.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-13-9780123969811.jpg)

Figure 3.13 Newssift used natural language processing to identify named entities and sentiment.

Another way to improve the experience of searching unstructured content is to **organize the results into thematic clusters**. For example, the query “genesis” on the Metasearch engine Yippy returns a number of clusters based around themes such as religion, music, cars, and so on (shown in the left-hand panel of Figure 3.14).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-14-9780123969811.jpg)

Figure 3.14 Concept clusters for the query “genesis” on Yippy.

#### Aggregate information
In business intelligence and other analytics applications, for example, the goal is not so much to find individual records but to identify patterns of distribution across the collection as a whole.

In these and other analytic applications, the focus of the search experience shifts from finding and evaluating individual results to standing back and gaining a more `holistic understanding`.

Our visual system is hard-wired to perceive certain visual attributes without any conscious effort. These `preattentive attributes` include shape and color.

We can use this knowledge to our advantage in designing complex search applications, particularly those that involve the display of quantitative information (such as the Newssift example mentioned earlier). If we want to communicate certain patterns visually, or make them stand out from the background, we should use preattentive attributes. Figure 3.17 shows a more comprehensive list of such attributes that can be used in this manner (Few, 2004).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-17-9780123969811.jpg)

Figure 3.17 Preattentive attributes of visual perception.

However, not all attributes are created equal: some are more suited to the display of quantitative information than others (Cleveland and McGill, 1984). The relative strengths of the various preattentive attributes are indicated in Figure 3.18.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-18-9780123969811.jpg)

Figure 3.18 The accuracy of quantitative perception for various preattentive attributes.

## 4.Modes of Search and Discovery
![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-01-9780123969811.jpg)

Figure 4.1 Search involves the activities of information retrieval, analysis, and sensemaking.

### Search Modes and Frameworks
One of the key insights of Marcia Bates’ dynamic model (introduced in Chapter 2) is that information seeking is essentially a nonlinear process in which information needs are not satisfied by a single, ideal set of documents but by an aggregation of learning and insight gathered along the way. In subsequent work, Bates extended this framework to accommodate a more sophisticated set of activities, which she referred to as moves, tactics, stratagems and strategies (Bates, 1990), defined as follows:

- Move: an atomic thought or action, such as entering a particular keyword
- Tactic: a collection of moves, such as broadening a search through the use of a more generic keyword
- Stratagem: a composite of moves and/or tactics, such as identifying a promising information resource and scanning it for further relevant items
- Strategy: a plan for an entire search, consisting of moves, tactics and/or stratagems

O’Day and Jeffries, for example, examined the information seeking strategies employed by clients of information professionals, and identified three primary categories of search behavior (1993):

1. Monitoring a known topic or set of variables over time
2. Following a specific plan for information gathering
3. Exploring a topic in an undirected fashion

O’Day and Jeffries investigated search as a holistic process, integrating findability with analysis and sensemaking (as illustrated in Figure 4.1). As part of this research, they studied the analysis techniques employed by searchers in interpreting their results and identified six categories:

1. Looking for trends or correlations
2. Making comparisons
3. Experimenting with different aggregations/scaling
4. Identifying critical subsets
5. Making assessments
6. Interpreting data to find meaning

A further influential framework is that proposed by Gary Marchionini (2006), who developed a model consisting of three major categories of search activity: Lookup, Learn, and Investigate (Figure 4.2).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-02-9780123969811.jpg)

Figure 4.2 Marchionini’s taxonomy of search activities.

Joe Lamantia, for example, analyzed the behaviors of subscribers to a complex financial information service, and identified four primary modes of interaction (Lamantia, 2006):

- Seeking information: conventional keyword search, plus related activities such as faceted navigation
- Visiting stable destinations: accessing persistent resources or locations within the information space
- Monitoring notifications: maintaining awareness of events, activity, status, and so on
- Receiving delivered assets: accepting content via various channels, such as email, RSS, and others

Donna Spencer undertook a similar analysis (Spencer, 2006), inspired by the observation that the traditional information science framing of known item versus exploratory search did not adequately account for the behaviors she was witnessing in her work on designing intranets and complex websites. She observed that in many practical situations, “people didn’t necessarily know what they needed to know” and that much of the search behavior she was observing was actually concerned with trying to refind resources that had previously been discovered. From this observation, she proposed the following set of four search modes:

1. Known item: in which users know what they want, how to articulate it, and where to look
2. Exploratory: in which users have some idea of what they want, but not necessarily how to articulate it or where to look
3. Don’t know what you need to know: in which users may start with one particular goal in mind, but need to replace it with another if and when they discover some key insight
4. Refinding: in which users know what they want when they see it, but not necessarily how to articulate it or where to look

Item 3 suggests an intriguing possibility, encapsulating the activities and outcomes associated with the elusive quality we commonly refer to as `serendipity`.

In particular, we have studied user scenarios gathered during the development of numerous search and business intelligence applications (Russell-Rose, Lamantia, and Burrell, 2011), and from this derived a set of nine search modes.

These modes are shown in the following list, grouped according to the three top-level categories proposed by Marchionini (2006):

- Lookup
  - 1 Locate: To find a specific (possibly known) item
  - 2 Verify: To confirm that an item meets some specific, objective criterion
  - 3 Monitor: To maintain awareness of the status of an item for the purposes of management or control
- Learn
  - 4 Compare: To examine two or more items to identify similarities and differences
  - 5 Comprehend: To generate independent insight by interpreting patterns within a data set
  - 6 Explore: To investigate an item or data set for the purpose of knowledge discovery
- Investigate
  - 7 Analyze: To examine an item or data set to identify patterns and relationships
  - 8 Evaluate: To use judgement to determine the value of an item with respect to a specific goal
  - 9 Synthesize: To create a novel or composite artefact from diverse inputs

### Designing for Search Modes
#### Lookup: verify
In this mode, the user is inspecting a particular item and wishing to confirm that it meets some specific criterion. Google’s image results page provides a good example of this mode (Figure 4.3).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-03-9780123969811.jpg)

Figure 4.3 Google’s image results page supports verification of a specific item.

On mouse hover, the image is zoomed in to show a magnified version along with key metadata, such as filename, image size, caption, and source, which allows the user to verify the suitability of a specific result and either retrieve it there and then or rapidly switch to alternatives.

A similar example is provided by Netflix (Figure 4.4), which also supports a mouse rollover interaction on its result page. In this case, a dialog overlay is used to verify the film’s title and provide further key metadata in the form of a summary, credits, rating, and so on.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-04-9780123969811.jpg)

Figure 4.4 Netflix’s results page supports verification of specific film choices.

Alternatively, there may be cases in which the user needs to verify specific queries rather than search results. With its real-time feedback after every key press, Google Instant provides verification of the interpretation of the current query and the results that will be returned (Figure 4.5).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-05-9780123969811.jpg)

Figure 4.5 Google Instant provides support for verification of queries and results.

#### Learn: explore
A key part of exploring is **being able to distinguish between where you are going and where you have already been**.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-06-9780123969811.jpg)

Figure 4.6 Differentiating between visited and unvisited links aids exploration.

Amazon takes support for exploration a step further, through the use of components specifically designed to provide information regarding the user’s current location and previous navigational history. These include a Recent History panel, which shows the items recently viewed by the user (Figure 4.7) and a Recent Searches panel, in which the user can view or invoke any the queries previously issued in the current session (Figure 4.8). Along with the wishlist functionality, these components provide support for the “refinding” behavior identified by Donna Spencer.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-07-9780123969811.jpg)

Figure 4.7 Amazon supports exploration by showing recently viewed items.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-08-9780123969811.jpg)

Figure 4.8 Amazon supports exploration by showing recent searches.

Another simple technique for encouraging exploration is through the use of “see also” panels. An example of this usage can be seen at Food Network, where a query for “ice cream” returns featured videos and products from the Food Network store alongside the primary search results (Figure 4.9).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-09-9780123969811.jpg)

Figure 4.9 “See Also” panels support serendipitous browsing and exploration.

Beyond the page level, there is a further approach we can apply: changing the search paradigm itself. Consider the library site illustrated in Figure 4.10: it uses a `parametric` interface in which users are invited to enter values for each of the attributes in the dropdown menus, then click the search button.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-10-9780123969811.jpg)

Figure 4.10 Parametric search inhibits exploration.

Consider the library site shown in Figure 4.11. In this instance, they have adopted a `faceted` approach, in which the attributes are not hidden behind dropdown menus but displayed as links in a navigational menu. This approach enables users to intuitively explore by progressively refining their choices in each dimension.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-11-9780123969811.jpg)

Figure 4.11 Faceted search facilitates exploration.

#### Investigate: analyze
A simple example of support for this can be found at Google patents (Figures 4.12a and 4.12b). The alternate views (Grid View and List View) allow the user to switch between rapid exploration (scanning titles, browsing thumbnails, looking for information scent) and a more detailed analysis of each record and its metadata.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-12-9780123969811.jpg)

Figure 4.12a, b Alternate views at Google Patents support mode switching between exploration and analysis.

He now wishes to analyze some of the prior art associated with a particular technology and understand how it has been reported in the media. He may turn to a news aggregator site such as the now-defunct Newssift.com (which was in its time a unique resource—see Figure 4.13).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-13-9780123969811.jpg)

Figure 4.13 Support for analysis at Newssift.com.

### Mode Chains and Patterns
Five example mode chains from the domain of enterprise search are listed here, with an associated example scenario (Russell-Rose, Lamantia, & Burrell, 2011):

1. Comparison-Driven Search (Analyze-Compare-Evaluate): “Replace a problematic part with an equivalent or better part without compromising quality and cost”
2. Exploration-Driven Search (Explore-Analyze-Evaluate): “Identify opportunities to optimize use of tooling capacity for my commodity/parts”
3. Strategic Insight (Analyze-Comprehend-Evaluate): “Understand a lead’s underlying positions so that I can assess the quality of the investment opportunity”
4. Strategic Oversight (Monitor-Analyze-Evaluate): “Monitor and assess commodity status against strategy/target”
5. Comparison-Driven Synthesis (Analyze-Compare-Synthesize): “Analyze and understand market trends to inform brand strategy and communications plan”

We can represent this grammar visually, as in Figure 4.14, which shows how the various sequences combine to form a “mode network.”

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-14-9780123969811.jpg)

Figure 4.14 A network of search modes.

### Designing for Mode Chains
Our experience suggests both the existence of repeatable patterns in information seeking behavior and the potential to apply these patterns as a framework for the design of search experiences (Russell-Rose, Lamantia, & Burrell, 2011). The implications of such a grammar could be considered at three levels of abstraction:

- A single functional element
- A complete screen composed of multiple functional elements
- An integrated application composed of multiple screens

# 2.Design Solutions
## 5.Formulating the Query
### Entering the Query
#### The search box
One of the fundamental concepts in human–computer interaction (HCI) is the notion of `affordance`: the idea that an object’s design should suggest the interactions that its `function` supports.

Likewise, the design of the search box should follow its function. If its purpose is to allow the user to enter queries in the form of keywords, then it should look like it will accept textual input and have an associated button that clearly indicates its function, as in Figure 5.1. The examples in Figure 5.2, by contrast, are less functional. The search box should also be wide enough to avoid obscuring parts of the query: Jakob Nielsen suggests that a minimum of 27 characters is required to accommodate 90 percent of queries (Nielsen & Loranger 2006).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-01-9780123969811.jpg)

Figure 5.1 A match between form and function at eBags.com.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-02-9780123969811.jpg)

Figure 5.2 Less conventional search box designs.

On the web, users can search for almost anything, with few constraints over topic or medium. By contrast, in site search (i.e., search of a specific website), the choices are usually much more restricted, which presents an opportunity to provide further support in the form of “placeholder” text and other prompts to help users construct meaningful queries.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-07-9780123969811.jpg)

Figure 5.7 Pipl search box guides users toward meaningful queries.

#### Scoped search
![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-08-9780123969811.jpg)

Figure 5.8 Search can be restricted to a specific category on eBay.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-09-9780123969811.jpg)

Figure 5.9 Scoped search at classified advertisement site Craigslist.

Users with high `domain expertise` (see Chapter 1) can therefore benefit greatly from scoped search, particularly if they are seeking known items.

#### Search within
By allowing users to search within an existing set of results, the query acts as a kind of refinement, narrowing down the results in a manner similar to that of faceted navigation (see Chapter 7).

For this reason, search within is often presented as a dedicated search box within the faceted navigation menu (Figure 5.11).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-11-9780123969811.jpg)

Figure 5.11 Search within is part of the faceted navigation menu at dabs.com.

Alternatively, search within can be integrated with the standard search box, using a radio button or checkbox to toggle between the two different types of input (Figure 5.12).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-12-9780123969811.jpg)

Figure 5.12 Search within is invoked using a checkbox at bulbs.com.

#### Advanced search
When `parametric` search was originally conceived, its interaction was based around the notion of selecting parameters on an extended form. In this context, it may have made sense to withhold some choices from the default view and present them instead as an advanced option (Figure 5.14).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-14-9780123969811.jpg)

Figure 5.14 Advanced search form at WARC.

#### Beyond keywords
##### Natural language
One of the most intuitive is to express the query as you would to another human being, that is, as a natural language question or request. This kind of interaction was popularized by search engines such as Ask (formerly Ask Jeeves), which uses a combination of text analytics and human moderation to produce a question-answering search experience (Figure 5.15).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-15-9780123969811.jpg)

Figure 5.15 Natural language question answering at Ask.

Wolfram Alpha uses NLP to answer factual queries by computing answers and relevant visualizations from a knowledge base of curated, structured data (Figure 5.16).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-16-9780123969811.jpg)

Figure 5.16 Natural language question answering at Wolfram Alpha.

##### Nontext queries
![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-17-9780123969811.jpg)

Figure 5.17 Search by example using images at Google.

Each of these services represents a type of search known as `query by example`.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-18-9780123969811.jpg)

Figure 5.18 Search by color at Etsy.

### Refining the Query





















