![cover](https://img9.doubanio.com/view/subject/s/public/s24920254.jpg)

    作者: Tony Russell-Rose / Tyler Tate
    出版社: Morgan Kaufmann
    副标题: The Information Architecture of Discovery
    出版年: 2013-1-2
    页数: 320
    定价: USD 39.95
    装帧: Paperback
    ISBN: 9780123969811

- [豆瓣](https://book.douban.com/subject/11638263/)
- [oreilly](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/)

---

- [1.A Framework for Search and Discovery](#1a-framework-for-search-and-discovery)
  - [1.The User](#1the-user)
    - [Novices and Experts](#novices-and-experts)
      - [Domain expertise versus technical expertise](#domain-expertise-versus-technical-expertise)
      - [Double novices orienteer](#double-novices-orienteer)
      - [Double experts teleport](#double-experts-teleport)
      - [The in-betweeners](#the-in-betweeners)
      - [Serial and holistic thinkers](#serial-and-holistic-thinkers)
      - [The rod-and-frame test](#the-rod-and-frame-test)
      - [Serialists: brick-by-brick craftsmen](#serialists-brick-by-brick-craftsmen)
      - [Holists: big-picture visionaries](#holists-big-picture-visionaries)
      - [The performance gap](#the-performance-gap)
      - [Designing for learnability](#designing-for-learnability)
    - [Verbal and Visual Learners](#verbal-and-visual-learners)
      - [From five senses to three modalities](#from-five-senses-to-three-modalities)
      - [Dual coding theory](#dual-coding-theory)
      - [Designing with overviews and previews](#designing-with-overviews-and-previews)
  - [2.Information Seeking](#2information-seeking)
    - [Models of Information Seeking](#models-of-information-seeking)
      - [The classic model](#the-classic-model)
      - [The standard model](#the-standard-model)
      - [The cognitive model](#the-cognitive-model)
      - [The dynamic model](#the-dynamic-model)
      - [The information journey model](#the-information-journey-model)
    - [Information Foraging](#information-foraging)
      - [A biological foundation](#a-biological-foundation)
      - [Man the informavore](#man-the-informavore)
      - [Information foraging theory](#information-foraging-theory)
      - [Designing with information scent](#designing-with-information-scent)
        - [Descriptive titles](#descriptive-titles)
        - [Hit highlighting](#hit-highlighting)
        - [Clear labeling](#clear-labeling)
    - [Sensemaking](#sensemaking)
      - [Human memory](#human-memory)
      - [Four stages of the sensemaking process](#four-stages-of-the-sensemaking-process)
      - [From internal to external schemas](#from-internal-to-external-schemas)
      - [Designing for sensemaking](#designing-for-sensemaking)
        - [The shoebox](#the-shoebox)
        - [The evidence file](#the-evidence-file)
        - [The schema](#the-schema)
    - [Stages of Information Seeking](#stages-of-information-seeking)
      - [The six-stage funnel](#the-six-stage-funnel)
      - [Designing for the journey](#designing-for-the-journey)
        - [Open-ended exploration](#open-ended-exploration)
        - [Information management](#information-management)
        - [Monitoring](#monitoring)
  - [3.Context](#3context)
    - [A Framework for Context](#a-framework-for-context)
    - [A Context-Based Model of Search](#a-context-based-model-of-search)
      - [Four layers of context](#four-layers-of-context)
        - [The information retrieval layer](#the-information-retrieval-layer)
        - [The information seeking layer](#the-information-seeking-layer)
        - [The work task layer](#the-work-task-layer)
        - [The cultural layer](#the-cultural-layer)
      - [Designing across layers](#designing-across-layers)
    - [Physical Context](#physical-context)
      - [Here and now](#here-and-now)
        - [Spatial context](#spatial-context)
        - [Temporal filters](#temporal-filters)
      - [Push versus pull](#push-versus-pull)
    - [The Information Landscape](#the-information-landscape)
      - [Content frameworks](#content-frameworks)
      - [Unstructured information](#unstructured-information)
      - [Aggregate information](#aggregate-information)
  - [4.Modes of Search and Discovery](#4modes-of-search-and-discovery)
    - [Search Modes and Frameworks](#search-modes-and-frameworks)
    - [Designing for Search Modes](#designing-for-search-modes)
      - [Lookup: verify](#lookup-verify)
      - [Learn: explore](#learn-explore)
      - [Investigate: analyze](#investigate-analyze)
    - [Mode Chains and Patterns](#mode-chains-and-patterns)
    - [Designing for Mode Chains](#designing-for-mode-chains)
- [2.Design Solutions](#2design-solutions)
  - [5.Formulating the Query](#5formulating-the-query)
    - [Entering the Query](#entering-the-query)
      - [The search box](#the-search-box)
      - [Scoped search](#scoped-search)
      - [Search within](#search-within)
      - [Advanced search](#advanced-search)
      - [Beyond keywords](#beyond-keywords)
        - [Natural language](#natural-language)
        - [Nontext queries](#nontext-queries)
    - [Refining the Query](#refining-the-query)
      - [Autocomplete](#autocomplete)
      - [Autosuggest](#autosuggest)
      - [Instant results](#instant-results)
    - [Keeping on Track](#keeping-on-track)
      - [Did you mean](#did-you-mean)
      - [Autocorrect](#autocorrect)
      - [Partial matches](#partial-matches)
      - [Related searches](#related-searches)
  - [6.Displaying and Manipulating Results](#6displaying-and-manipulating-results)
    - [Displaying Search Results](#displaying-search-results)
      - [Basic principles](#basic-principles)
      - [The anatomy of a search result](#the-anatomy-of-a-search-result)
      - [Search result previews](#search-result-previews)
      - [Answers and shortcuts](#answers-and-shortcuts)
    - [Search Results Pages](#search-results-pages)
      - [Basic principles](#basic-principles-1)
      - [Page layouts](#page-layouts)
      - [Blended results](#blended-results)
      - [Zero results pages](#zero-results-pages)
    - [Manipulating Search Results](#manipulating-search-results)
      - [Pagination](#pagination)
      - [Sorting and filtering](#sorting-and-filtering)
      - [Query clarification](#query-clarification)
      - [Comparing](#comparing)
  - [7.Faceted Search](#7faceted-search)
    - [Definitions](#definitions)
      - [Facet semantics](#facet-semantics)
      - [Facet states and behaviors](#facet-states-and-behaviors)
    - [Layout](#layout)
      - [Vertical layout](#vertical-layout)
      - [Horizontal layout](#horizontal-layout)
      - [Hybrid layout](#hybrid-layout)
    - [Default State](#default-state)
      - [Closed by default](#closed-by-default)
      - [Open by default](#open-by-default)
      - [Open/closed hybrid](#openclosed-hybrid)
    - [Display Formats](#display-formats)
      - [Hyperlinks](#hyperlinks)
      - [Checkboxes](#checkboxes)
      - [Range sliders](#range-sliders)
      - [Input boxes](#input-boxes)
      - [Color pickers](#color-pickers)
      - [Tag clouds](#tag-clouds)
      - [Data visualizations](#data-visualizations)
    - [Showing Additional Values](#showing-additional-values)

# 1.A Framework for Search and Discovery
The most fundamental step is to recognize that the opinions are themselves based on a set of **assumptions**—in particular, assumptions about **who** is doing the searching, **what** they are trying to achieve and under **what circumstances**, and **how** they are going about it. Each of these assumptions corresponds to a separate `dimension` by which we can define the search experience.

**The Dimensions of Search User Experience**

The first of these dimensions is the `type of user`, in particular his or her level of **knowledge and expertise**.
For example, consider the users of an online retail store: are they knowledgeable enthusiasts or novice shoppers? Likewise, for an electronic component supplier: are the users expert engineers or purchasing agents with limited domain knowledge?

Once we understand the user, we can move on to the second dimension: his or her `goal`. This goal can vary from simple fact checking to more complex explorations and analyses. For example, are users searching for a specific item such as the latest Harry Potter book? Or are they looking to choose from a broader range of possibilities, such as finding shoes to match a business suit? Or are they unsure of what they are looking for in the first place, knowing only that they would like to find a suitable gift?

Knowing the users and their goals, we can now consider the third dimension: the `context`. Context includes a range of influences, from the physical to the intangible. For example, is the user at the workplace, where the task and the organizational setting dominate? Or is the user at home, where `social context` might become more important? Perhaps he or she is using a mobile device while travelling, during which `physical context` shapes the search experience.

Finally, based on our understanding of the users, their task and the wider context, we can consider the fourth dimension: their `search mode`. Search isn’t just about finding things—on the contrary, most finding tasks are but a small part of a much larger overall task. Consequently, our focus must be on understanding the complete task life cycle and helping users complete their overall information goals. This includes activities such as comparing, exploring, evaluating, analyzing, and much more.

## 1.The User
### Novices and Experts
Expertise plays a significant role in how people seek information. Understanding the differences between novices and experts will enable us to design better search experiences for everyone. But first, it’s worth distinguishing between two dimensions of expertise.

#### Domain expertise versus technical expertise
`Domain expertise` defines one’s familiarity with a given subject matter; a professional photographer, for instance, has substantial domain expertise in the field of photography. `Technical expertise`, on the other hand, indicates one’s proficiency at using computers, the Internet, search engines, and the like.

In combination, the domain and technical dimensions of expertise describe four types of users (Figure 1.1):

- Double experts
- Domain expert/technical novices
- Domain novice/technical experts
- Double novices

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-01-9780123969811.jpg)

Figure 1.1 Two dimensions of expertise: domain and technical.

#### Double novices orienteer
Double novices share three main characteristics (Hölscher and Strube, 2000):

1. **Frequent query reformulation**. Novices perform more queries than experts but look at fewer pages. Although they frequently reformulate their query, double novices often make only small, inconsequential changes to their search phrase.
2. **Going back**. When novices do click on a search result, they are much more likely than experts to then navigate back to the search page. With a fear of venturing too far from safety, double novices practice a hub-and-spoke pattern of information seeking with the search page firmly at the center.
3. **More time spent**. The many queries and frequent backward-oriented behavior of double novices causes them to spend more time on a given search task than would an expert.

Because novices frequently refine their original query but often don’t make radical enough changes, showing a list of related searches (as demonstrated by Foodily in Figure 1.2) can help users make more successful query reformulations. In addition, breadcrumbs accomplish the dual purpose of communicating the user’s current location, while also providing a path to go back (Figure 1.3).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-02-9780123969811.jpg)

Figure 1.2 Foodily’s iPhone application places related searches at the bottom of the page, after the search results.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-03-9780123969811.jpg)

Figure 1.3 The breadcrumbs on Zappos.com indicate which filters the user has applied and provide the means to remove them.

#### Double experts teleport
Double experts are characterized by three tendencies (Hölscher and Strube, 2000):

1. **More pages examined**. Double experts click on more search results than do novices.
2. **Going deeper**. Double novices tend to retreat from the pages they examine; double experts rarely go back. Instead, experts follow links from one page to the next, progressing deeper into the information space with each step.
3. **Less time spent**. Double experts are time-efficient in their search tasks. Not only do they reformulate their queries less often, but they can also determine the relevancy of a given page more rapidly than novices.

Expert-friendly search user interfaces should support advanced syntax and filtering to help users quickly narrow their search. Although the Boolean operators AND, OR, and NOT are certainly worth supporting, Wolfram Alpha (shown in Figure 1.4) goes a step further and allows users to input domain-specific terminology and retrieve computed answers. Similarly, a faceted search interface for filtering by format, selecting ranges, or excluding certain categories—such as Getty’s Moodstream, shown in Figure 1.5—can help users pinpoint content that’s relevant to their information needs.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-04-9780123969811.jpg)

Figure 1.4 Wolfram Alpha is designed to return computed answers using advanced syntax and domain-specific terminology.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-05-9780123969811.jpg)

Figure 1.5 Getty Image’s Moodstream lets users search for stock photos using slider controls.

#### The in-betweeners
Domain expert/technical novices, for instance, use their knowledge to enter effective queries and quickly evaluate pages, but they lack the technical confidence to explore unknown territory (Jenkins et al., 2003). Their traits include:

1. **Advanced terminology**. Domain experts are able to rely on their extensive vocabulary to construct more topical queries than are domain novices.
2. **Effective evaluation**. Similarly, high domain knowledge makes the process of evaluating a page more meaningful and timely.
3. **Going back**. A lack of technical expertise, however, contributes to a sense of disorientation, preventing users from venturing too far away from the search page.

Domain novice/technical experts, on the other hand, brim with confidence, but have trouble discerning relevant content (Hölscher and Strube, 2000). They are characterized by:

1. **Advanced formatting**. Technical experts are much more likely to use query formatting techniques—such as double quotes and Boolean operators—than are technical novices.
2. **Confident exploration**. Despite their lack of domain expertise, technical experts exude confidence and never worry about becoming disoriented.
3. **Difficulty with evaluation**. Technical expertise doesn’t compensate for a lack of domain knowledge when it comes to evaluating the relevance of a page.

#### Serial and holistic thinkers
Psychologists call these `cognitive styles`—the stable attitudes, preferences, and habits that determine how an individual processes and represents information. We’ll begin by looking at the `serial-holistic style` of information processing.

#### The rod-and-frame test
Here it is: draw a vertical line inside the rectangle.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-06-9780123969811.jpg)

Figure 1.6 Complete a simplified version of the rod-and-frame test by drawing a vertical line in the rectangle.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-07-9780123969811.jpg)

Figure 1.7 Serialists complete the rod-and-frame test by drawing the line aligned with the edges of the rectangle (left). Holists, on the other hand, draw the line along the global north–south axis (right).

#### Serialists: brick-by-brick craftsmen
Like skilled craftsmen, serialists are highly attuned to the details. When learning, serialists tend to drill down to narrow subtopics and follow a logical progression from one to the next. Despite being skilled at analyzing the component parts (Figure 1.8), serialists have greater difficulty combining the parts into a whole (Kim, 2001).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-08-9780123969811.jpg)

Figure 1.8 Serialists concentrate on the individual parts rather than the whole.

#### Holists: big-picture visionaries
Holists are visionaries with a bird’s-eye view (Figure 1.9). Operating with an intrinsic motivation that is independent of their surroundings, holists flourish in flexible environments where they are free to pursue their own interests at the pace of their choice. When approaching a topic, they immediately set out to comprehend the big picture, giving holists a more balanced view and helping them put situations into context. However, holists are also prone to oversimplification, sometimes glossing over important details (Ford et al., 2002).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-09-9780123969811.jpg)

Figure 1.9 Holists focus on the cohesive whole rather than on component parts.

#### The performance gap
Holists are more efficient at satisfying their information needs. Serialists, by comparison, find it more difficult to discern the relevance of information and consequently spend more time searching for the same answers.

Although there is a wide gap in performance between serialists and holists who are `technical novices`, the gap all but disappears between the two cognitive styles when `technical expertise` is high. In other words, user interfaces can become more effective by helping serialist novices—or all novices, for that matter—increase their level of technical expertise.

#### Designing for learnability
`Learnability`—the ease with which users gain awareness of available software functions and comprehend how to act on them—can be accomplished using `contextual instructions`, `immersive overlays`, and `subtle visual design`.

A simple contextual instruction, for example, can be achieved by adding descriptive placeholder text to the search box (Figure 1.10). The text can inform users about the type of query that the system expects—whether it’s the name of a restaurant, an area of a city, or a postal code.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-10-9780123969811.jpg)

Figure 1.10 Toptable’s iPhone application combines the use of placeholder text and a three-option segmented control to clearly indicate the type of input that the application expects from the user.

`Contextual popovers`, like the ones used by Foodily in Figure 1.11, can augment a well-designed interface and reduce the guesswork required by the user. `Immersive, full-screen overlays` —such as the welcome screen to the TapTu iPad app shown in Figure 1.12—can serve a similar purpose. Caution is required in both situations, however; providing tips for new users must be balanced with concern for more experienced users (both Foodily and TapTu, for instance, show the “getting started” advice only on a user’s first visit).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-11-9780123969811.jpg)

Figure 1.11 Foodily, a recipe search site, uses small popovers to introduce first-time users to a few of the features unique to Foodily’s website.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-12-9780123969811.jpg)

Figure 1.12 TapTu, a news-reading application, uses an overlay to provide a tutorial for new users.

A more nuanced method for enhancing learnability is to use subtle animation and tactile textures to suggest gestures, hint at off-screen content, and indicate which elements on the screen are interactive. When a user first views a list of search results using Airbnb’s iPhone application (shown in Figure 1.13), for instance, an animation reveals a star behind each result before quickly disappearing, hinting that a swipe from left to right will “favorite” that particular item. Such tactics are especially useful on mobile devices where screen space is scarce.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-13-9780123969811.jpg)

Figure 1.13 On the first use, Airbnb’s iPhone application reveals a star behind each search result before quickly sliding away, training users to use a left-to-right gesture to “favorite” a result.

### Verbal and Visual Learners
![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-14-9780123969811.jpg)

Figure 1.14 Two dimensions of cognitive style: serial–holistic and verbal–visual.

#### From five senses to three modalities
We experience the world through five senses, distilled by psychologists into three “sensory modalities” relevant to learning: verbal, visual, and kinesthetic (Denig, 2004). Though everyone learns through all three modes, we each favor one over the others, resulting in three different styles of learning:

1. `Verbal` learners absorb written and spoken information more readily than visual concepts. Because most learning is either text-based (reading a book, searching online) or auditory (a classroom lecture or personal conversation), verbal learners have ready access to content in their preferred medium.
2. `Visual` learners, on the other hand, digest information from charts, diagrams, timelines, maps, and other concrete images more easily than from the written or spoken word. Visual learners have less access to appropriate content than their verbal counterparts.
3. `Kinesthetic` learners enjoy hands-on activities involving movement, from dancing to woodwork. Although kinesthetic learning is minimally involved in desktop computing, it plays a much more significant role in gestural and touch-based interfaces.

#### Dual coding theory
In the 1970s, psychologist Allan Paivio made an important observation: people learn best when information is presented in two modalities at the same time, which is now known as the `Dual-Coding Theory`. 

#### Designing with overviews and previews
Although dual coding theory has significant implications for website content, it’s also important for the search experience. In particular, `visual overviews` and `previews` can augment text-based lists to both describe the result set as a whole, as well as the individual result itself (Greene et al., 2000).

Mapumental, for example, distills transit times, house prices, and “scenicness” ratings into a composite map overlay that helps its users choose where to live. Crunching these numbers oneself would be an enormous task, yet the map in Figure 1.15 instantly shows which areas of London are no farther than a 45-minute commute from Waterloo Station, have an average house price of less than £400,000, and score at least 2 out of 10 in scenicness.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-15-9780123969811.jpg)

Figure 1.15 Mapumental visualizes a synthesis of transit times, house prices, and “scenicness” ratings to help users choose where to live.

Google Finance’s stock screener, for example (shown in Figure 1.16), efficiently combines dual sliders with a histogram to provide contextual feedback for users searching for companies by financial criteria.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-16-9780123969811.jpg)

Figure 1.16 Histograms, such as these from Google Finance’s stock screener, instantly convey the distribution of results.

While `overviews` provide a visual depiction of the result set as a whole, `previews` help the user examine an individual result in greater detail—augmenting verbal information with a visual component to help the user make better relevance judgments. In some cases—such as ecommerce—visual thumbnails can even be more important than the text (Figure 1.17).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-17-9780123969811.jpg)

Figure 1.17 For many ecommerce websites, such as NorthFace.com, visual thumbnails are more important than textual descriptions.

Larger previews, rather than help the user quickly skim the results, gives the user a chance to verify the relevance of a result before committing to viewing the full item. Apple’s Spotlight search, for example (shown in Figure 1.18), previews a document as the user hovers over its title, reducing the inconvenience of opening a new document only to discover that it’s irrelevant.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F00001Xf01-18-9780123969811.jpg)

Figure 1.18 Apple’s Spotlight search shows document previews as the user interacts with the search results.

## 2.Information Seeking
Mankind is an endless pursuer of knowledge.

We bridge this knowledge gap by asking those around us for advice, turning to books and encyclopedias, and, increasingly, searching the Internet. This journey between need and fulfillment is called `information seeking`.

### Models of Information Seeking
#### The classic model
The classic model is one of the first models of information retrieval, widely used in information science research for over 30 years (Robertson, 1977).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-01-9780123969811.jpg)

Figure 2.1 The classic model of information retrieval.

#### The standard model
In contrast with the classic model, the standard model places greater emphasis on the user. It portrays information seeking as a type of problem solving (Marchionini, 1995) involving a cycle of four activities (Sutcliffe & Ennis, 1998):

1. Identifying the problem
2. Articulating the information need
3. Formulating the query
4. Evaluating the results

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-02-9780123969811.jpg)

Figure 2.2 The standard model of the search process.

#### The cognitive model
Like the standard model, Don Norman’s cognitive model of task performance (shown in Figure 2.3) also views search as a form of problem solving driven by an explicit user goal (Norman, 1988). But in this case, users apply a mental model—an internal representation of the problem situation and its context—to develop a plan of action to achieve that goal. These actions lead to changes in the external world that are evaluated to determine whether the goal has been achieved.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-03-9780123969811.jpg)

Figure 2.3 Don Norman’s cognitive model of task performance.

A key insight of Norman’s model over the previous two is that it recognizes the importance of domain knowledge (as discussed in Chapter 1): the greater the users’ knowledge, the more likely they are to articulate effective queries and accurately determine the relevance of results.

#### The dynamic model
Both the standard and cognitive models share an underlying assumption that the user’s information need remains unchanged throughout a given session. They view the process of information seeking as one of iteratively refining a given query until the ideal set of results is found. However, numerous studies have found that users’ information needs evolve as they interact with information and that they formulate new goals as they acquire domain knowledge. Far from being static, search is an interactive, iterative process in which the answer can change the question. As Peter Morville puts it, “what we find changes what we seek” (Morville, 2009).

Consequently, we need a model that accounts for changes in users’ information needs as they learn and respond to the information they encounter. The dynamic model proposed by Marcia Bates (1989) accomplishes just that (Figure 2.4).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-04-9780123969811.jpg)

Figure 2.4 Marcia Bates’ dynamic model.

#### The information journey model
Ann Blandford and Simon Attfield (2010) have further explored the unfolding journey of information seeking. Like the dynamic model, their information journey model (shown in Figure 2.5) has been derived from empirical studies of user behavior. The main activities in their framework are:

1. Recognizing an information need
2. Acquiring information
3. Interpreting and validating the information
4. Using the information

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-05-9780123969811.jpg)

Figure 2.5 The information journey model.

These information encounters are what we commonly label serendipity. The information journey model, with its multiple entry points, acknowledges `serendipity` as part of the information seeking experience.

### Information Foraging
`Information foraging`, an instinct closely related to that found in animals hunting for food, interacts with `sensemaking`, the cognitive process for deriving meaning from new information. Together, information foraging and sensemaking form a feedback loop (Pirolli & Card, 2005) that underpins the information seeking process.

#### A biological foundation
Biologists in the 1960s observed that animals often eat a particular type of food in one environment but ignore the same food in other places. Ecologists Robert MacArthur and Eric Pianka set out to discover how animals decide what to eat. Their research, and their accompanying `optimal foraging theory` (MacArthur & Pianka, 1966), provides a foundation for understanding our own behavior when searching for information.

According to optimal foraging theory, animals live in environments consisting of many “patches,” each with a unique blend of potential food sources.

This principle of diminishing returns is known in ecology as the `marginal value theorem` (Charnov, 1976). The theory asserts that animals perform a cost/benefit analysis on staying in the current patch versus traveling to a new one—considering both current and potential food supplies as well as the transit time between the two patches (Figure 2.6).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-06-9780123969811.jpg)

Figure 2.6 Charnov’s marginal value theorem states that a forager should leave a given patch when the rate of gain within that patch drops below the rate of gain that could be achieved by traveling to a new patch.

#### Man the informavore
George Miller portrayed our species as `informavores`: creatures hungry for information (Miller, 1983). But just like the bear must be selective in its diet (digging all day for a few measly ants would hardly be worthwhile), so must informavores carefully navigate the glut of information in our modern environment. Herbert Simon spoke of this perilous balance in 1971:

>What information consumes is rather obvious: it consumes the attention of its recipients. Hence a wealth of information creates a poverty of attention, and a need to allocate that attention efficiently among the over-abundance of information sources that might consume it. (p. 40)

Although information is what we seek, our limited supply of attention forces us to make a tradeoff between comprehensiveness and timeliness. Simon coined the term satisficing—a combination of the words “satisfy” and “suffice”—to describe this pragmatic decision-making strategy that pervades human behavior (Simon, 1956).

#### Information foraging theory
Peter Pirolli and Stuart Card, researchers at the Palo Alto Research Center (PARC), began applying the principles of optimal foraging theory to information seeking in the early 1990s, establishing a new framework called `information foraging theory` (Pirolli & Card, 1999). Pirolli and Card drew a connection between users moving from one website to the next and animals traveling from patch to patch. They observed that users, in an effort to satisfice, heavily rely on certain cues known as `information scent` to guide them toward their destination.

As users traverse the Web, they encounter information scent when `“trigger words”`—terms they perceive as meaningful to their task—are used in the text of a hyperlink, as words in a heading, or in a search result’s description. The more trigger words that are present, the stronger the information scent (Spool et al., 2004). When information scent grows stronger from page to page, users are confident that they’re headed in the right direction. But when it’s weak, they may be uncertain about what to do or even give up.

In addition to information scent, Pirolli and Card’s research also helps explain `information snacking` (Nielsen, 2003). According to the marginal value theorem, the amount of time a user spends on a given website is proportional to the travel time between sites. As between-patch time decreases—thanks to Google and fast Internet connections—users spend less time on any one site. The result is that information seeking has become less of a sit-down banquet and more of an opportunistic buffet.

#### Designing with information scent
##### Descriptive titles
Before clicking on a search result—or even reading its two-line description—the title must first be deemed relevant. Obvious though it is, the presentation of clear, descriptive titles is the surest method for providing strong information scent when displaying search results.

Jared Spool found that reasonably long titles tend to work better than shorter ones, with links of 7 to 12 words being most likely to lead to a successful outcome (Figure 2.7).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-07-9780123969811.jpg)

Figure 2.7 Jared Spool found that 7- to 12-word links yield the greatest likelihood of a user finding what he or she is looking for.

##### Hit highlighting
When the user performs a query, he or she inputs the most important terms to his or her search—that is, the query’s `trigger words`. Hit highlighting (Figure 2.8) is the technique of emphasizing the words included in the query wherever they appear on the search results page. Using a bold font weight helps to draw the user’s eye to the trigger words, increasing information scent.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-08-9780123969811.jpg)

Figure 2.8 Bing uses a bold font weight to highlight the user’s query terms whenever they appear in the search result list, for both exact phrase matches (e.g., “artificial intelligence”) and partial matches (e.g., “intelligence”).

##### Clear labeling
When searching through online content, for instance, the user might be looking for business news and wish to skip over sport and entertainment articles (Figure 2.9). Clearly identifying which category a given result belongs to can help users ignore unwanted documents and focus on their genre of choice (Drori, 2002).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-09-9780123969811.jpg)

Figure 2.9 The BBC labels each news story with a category, such as “Europe” or “Business.”

### Sensemaking
`Sensemaking`—a concept developed in the information science field by Brenda Dervin (1983) and in human–computer interaction by PARC researchers Daniel Russell and colleagues—describes the process through which people assimilate new knowledge into their existing understanding (Russell et al., 1993). Just as the study of information foraging behavior has led to techniques for designing more fluid search experiences, so can an appreciation of how people make sense of information help us design tools that facilitate comprehension, analysis, and insight.

#### Human memory
Most relevant for our purpose, however, is long-term `semantic` memory, which is responsible for keeping track of our ever-growing conceptual knowledge (Tulving, 1985). Semantic memory organizes knowledge into a schema of interconnected nodes that our minds can manipulate and explore at will (Miller, 1987), a simplistic visualization of which can be represented by mind map diagrams such as the one in Figure 2.10.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-10-9780123969811.jpg)

Figure 2.10 This mind map created on MindMeister.com visualizes one person’s understanding of western philosophy.

This internal semantic schema is constantly in flux. New information may require our semantic memory to add new nodes to the existing schema, reorganize the links between nodes, or discard concepts that are no longer pertinent. This is the realm of **sensemaking: growing, rearranging, and pruning the semantic tree of knowledge**.

#### Four stages of the sensemaking process
1. Search
2. Extract
3. Encode
4. Analyze

#### From internal to external schemas
Thus far, we’ve treated the semantic schema as the internal model of an individual’s knowledge. However, the finite capacity of the human mind ensures that one’s own understanding is only a subset of reality. In the same way that a map is a compact representation of a much larger landscape, so our internal semantic schema is a simplified sketch of a much broader body of knowledge.

Sophisticated information tasks demand that one’s `internal` semantic model be disseminated into an `external` schema. External schemas can not only store a greater amount of information than an internal schema, but can also serve as a conduit for collaboration.

#### Designing for sensemaking
##### The shoebox
The first step in many investigations is to gather potentially relevant documents into a single collection—what could be coined the shoebox (a term that recollects putting something away for later). At this stage, the analyst isn’t concerned with a close examination of each document; the top priority is to populate the shoebox as quickly as possible with anything that might be relevant to the investigation. The analyst heavily relies on information scent to make rapid judgments about which documents should and should not be included. To support this behavior, the user interface should enable the analyst to add documents to the shoebox as rapidly as possible. For instance a text link, checkbox, or icon (Figure 2.11) could be provided for quickly saving a given search result.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-11-9780123969811.jpg)

Figure 2.11 Airbnb.com places a star icon next to each search result. Clicking on the star saves that result to the user’s “favorites list.”

##### The evidence file
Once the shoebox has been populated with potentially relevant documents, the analyst often then begins a more thorough examination of the curated collection. This time around, the analyst spends significantly more time scrutinizing the text and images when looking for possible leads. When the analyst spots a striking sentence or meaningful image, he or she extracts that snippet and saves it to a more cogent collection of relevant information: the evidence file.

A simple example of an evidence file is Mendeley, a tool that helps academics manage their research. Mendeley provides a special bookmark that users can add to their web browsers (Figure 2.12). When clicked, a popup window appears and prompts the user to save a title, keywords, tags, and meaningful notes extracted from the current page.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-12-9780123969811.jpg)

Figure 2.12 Mendeley’s document import tool.

##### The schema
The external schema provides an even bigger picture of how the extracted evidence fits together. It may be constructed of the people, places, and events surrounding a crime or the causes and symptoms of a disease (Figure 2.13). Also known as an ontology—a specification of a shared conceptualization—the external schema enables analysts to continually explore, gain insights from, and test hypotheses against the model as it is constructed.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-13-9780123969811.jpg)

Figure 2.13 The “conditions and diseases” node of a much larger external semantic schema on the NHS Evidence website.

### Stages of Information Seeking
#### The six-stage funnel
Carol Kuhlthau, a professor at Rutgers University, performed a series of studies during the 1980s to better understand how people seek information to satisfy long-term goals (Kuhlthau, 1991). Kuhlthau identified distinct phases in what she called the `information search process` but is best described as stages of `information seeking` (Figure 2.14). She observed both the tasks and emotions unique to each of six phases:

1. Initiation
2. Selection
3. Exploration
4. Formulation
5. Collection
6. Action

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-14-9780123969811.jpg)

Figure 2.14 Kuhlthau’s six stages of information seeking can be represented as a funnel that begins open-ended and ends with a resolution.

#### Designing for the journey
##### Open-ended exploration
Whether the task is looking for a place to live, finding the perfect car, or planning a vacation, it’s unlikely that the user knows exactly which house is best, what car is ideal, or precisely where to go on holiday at the outset. Yet these are often the first questions that real estate, automotive, and travel sites ask us (Figure 2.15).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-15-9780123969811.jpg)

Figure 2.15 Autotrader.co.uk asks the user to specify an exact make and model of car up front.

In order to engage users earlier in their journey, we must help them explore (Marchionini, 2006). Flexible filtering controls can facilitate browsing without the need for an initial query, helping the user survey the information landscape and potentially make serendipitous discoveries along the way. Although automotive sites AutoTrader and Motors.co.uk both allow users to choose specific makes and models, the latter (Figure 2.16) also caters to those who haven’t yet formulated an exact specification, allowing them to filter by body style, color, number of doors, number of seats, and many other factors.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-16-9780123969811.jpg)

Figure 2.16 Motors.co.uk provides flexible filtering options, making it easy for users to look for cars even before deciding on a particular make and model.

##### Information management
Equipping users to bookmark, categorize, and annotate findings can greatly streamline the long-term information seeking process.

Bookmarking can help users refind items of interest at a later date. What’s more, grouping bookmarks into meaningful sets—like placing recipes into “meal plans” on Foodily (Figure 2.17)—can help users organize large collections of information. Ratings and annotations—such as the personal notes and one- to five-star rankings that can be added to saved properties on Globrix (Figure 2.18)—can further extend the user’s memory by making it easier to compare and differentiate saved items.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-17-9780123969811.jpg)

Figure 2.17 Foodily, a recipe search engine, allows users to save their favorite recipes and organize them into meal plans.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-18-9780123969811.jpg)

Figure 2.18 Property search site Globrix allows users to assign a rating and write notes on each property that they’ve bookmarked.

##### Monitoring
Applications can facilitate monitoring in two ways: on demand or automatically. Enabling the user to save a search query along with any applied filters provides a means for returning to that query `on demand` at a later date. Often, however, users may prefer to be `automatically notified` by email when a new match to their criteria appears, reducing the need to continually check back (eBay, pictured in Figure 2.19, provides both).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000021f02-19-9780123969811.jpg)

Figure 2.19 eBay allows users to save searches and, by checking a box, to be notified by email when new items are added.

## 3.Context
### A Framework for Context
Context can also be defined in terms of its constituent parts. Myrhaug and Goker (2003), for instance, propose a framework of five key components:

- Task. Any goals, tasks, actions or activities associated with what the user is doing.
- Spatiotemporal. Attributes relating to the current time, location, direction, and so on.
- Personal. The user’s physiological context, mental state, preferences, and so on.
- Social. The user’s role, status, and relationships with other individuals.
- Environmental. Factors including temperature, light, humidity, and, on a slightly different note, the information resources accessed by the user.

Frameworks such as this help us understand the role of context in search and form the basis for a principled approach to design. As Lieberman and Selker (2000) put it:

>A considerable portion of what we call…good design in human computer interaction actually amounts to being sensitive to the context in which the artifacts are used. Doing the “right thing” entails that it be right given the user’s current context. (p. 617)

### A Context-Based Model of Search
#### Four layers of context
Figure 3.1 presents an example of this influence based on the work of Jarvelin and Ingwersen (2004). This model represents the task context as a set of layers that start at the micro level (information retrieval) and extend outward to the macro level (culture).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-01-9780123969811.jpg)

Figure 3.1 A context-based model of search.

##### The information retrieval layer
At the most granular level of the model is information retrieval. This layer is typified by simple, focused tasks such as finding a specific document related to a keyword query.

These tasks are often referred to as `known item searches`. They may involve a number of iterations but are usually confined to a single session.

The success of tasks at this level is commonly evaluated using system-oriented metrics such as precision and recall.

##### The information seeking layer
At the next level is information seeking. This layer is associated with broader, more complex tasks that attempt to satisfy an information need or problem (Marchionini, 1995).

In this context, users need to exercise judgment regarding which strategies to adopt, such as where, how, and when to look for information (Wilson et al., 2010).

##### The work task layer
The information need that precipitates information seeking is itself motivated by a further level: the `work task`. This layer is characterized by higher-level tasks that are created when the user recognizes an information need based on either an organizational need or a personal motive (Marchionini, 1995).

Work tasks situated in an organizational setting are likely to reflect local resources, constraints, and working practices (Wilson et al., 2010). This list can include which resources are available to satisfy a given information need, such as reference materials, libraries, human experts, and others. Evaluation at this level focuses on assessing performance of the overall task.

##### The cultural layer
This level influences not only the overall task requirements but also the collective importance attached to meeting them.

#### Designing across layers
Unfortunately, tasks at this level are often poorly supported by online retailers, and a query for “home entertainment” returns an opaque list of product categories that relies on the user understanding the terminology and knowing which category to select (Figure 3.2).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-02-9780123969811.jpg)

Figure 3.2 Limited support for the work task level at Comet.

But behind the tab labeled “Videos and Advice” lies a resource (pluggedin.co.uk) that is much more appropriate for this level of task. Instead of product categories, a query for “home entertainment” here returns content much better suited to the immediate goal (Figure 3.3). This content includes tutorials in the form of buyer’s guides and how-to guides alongside product reviews and user-generated content from specialist forums. In contrast to the product category listing seen previously, this material provides far greater support for activities associated with the work task level, such as exploration and learning. In addition, it supports discovery of latent needs through the provision of aspirational articles and expert reviews.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-03-9780123969811.jpg)

Figure 3.3 Support for the work task level at pluggedin.co.uk.

Amazon, for example, supports iterative information seeking via a personalized history panel that includes recent searches and recently viewed items (Figure 3.4). This information is augmented by a facility for users to create, organize, and share their own lists.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-04-9780123969811.jpg)

Figure 3.4 Support for the information seeking level at Amazon.

As the user gets a clearer idea of his or her needs and identifies suitable products, he or she may wish to verify the price and quality of these particular items on independent sites. In this context, the focus shifts from information seeking to a set of specific information retrieval subtasks. This is the level that traditionally has been best supported by online retailers. One notable example of design support for information retrieval can be found at Samsung.com (Figure 3.5), which provides a particularly immersive style of instant results and autocomplete.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-05-9780123969811.jpg)

Figure 3.5 Support for the information retrieval level at Samsung.com.

### Physical Context
#### Here and now
Mobile user needs are driven by the spatiotemporal context: they seek results that are not just relevant to their immediate information need (i.e., topically relevant) but also timely and relevant to their physical location (Goker et al., 2004). These influences, coupled with an increased emphasis on precision over recall, suggest an approach in which these factors are combined to deliver the most contextually relevant results (Figure 3.6).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-06-9780123969811.jpg)

Figure 3.6 Topical, spatial, and temporal filters can be combined to increase the relevance of search results.

##### Spatial context
Spatial context can be modeled in a number of ways. One of the simplest approaches is to equate relevance with physical distance; that is, the closer the spatial footprint of a given item, the more relevant it is (Mountain and MacFarlane, 2007). This approach is offered by many directory services such as Yelp (Figure 3.7).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-07-9780123969811.jpg)

Figure 3.7 Physical distance as a measure of relevance.

Alternatively, spatial relevance could be based on physical accessibility, that is, the amount of time it takes to reach a particular location.

Moreover, spatial context of mobile users is rarely static; often the user is in transit during the interaction itself. In this case, it may be more appropriate to consider the user’s current trajectory and determine relevance based on the user’s predicted location at any point in time.

##### Temporal filters
Temporal context can be also modeled in a number of ways. One of the most intuitive approaches is to equate relevance with “freshness”; This approach could be combined with the spatial footprint to provide a feed of breaking news specific to the user’s current locality (Figure 3.8).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-08-9780123969811.jpg)

Figure 3.8 The Associated Press combines temporal relevance with spatial relevance.

Some types of information have a predictable schedule associated with them, such as the timetables for public transport or the opening hours for shops and services. There is little value in finding restaurants that are currently closed or trains that are no longer running. In order to utilize this type of context, it is necessary to filter results according to the time when the user wishes to travel or partake of the particular service.

#### Push versus pull
Information doesn’t always have to be `pulled` by users in this way. Given knowledge of their preferences, it is possible to `push` information to users whenever it becomes relevant to their physical context. For example, Foursquare, a location-based social network for mobile users, provides real-time push notifications when friends “check in” at various locations (Figure 3.9).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-09-9780123969811.jpg)

Figure 3.9 Foursquare provides push notification of location-based updates.

Location-based advertising is the ultimate example: from a marketing perspective, it offers almost unlimited potential for presenting contextually relevant promotions to consumers based on their current location. However, this type of service will be tolerated only if the relevance and value of the information outweighs the cost of the intrusion and the associated lack of privacy (Figure 3.10).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-10-9780123969811.jpg)

Figure 3.10 Location-based promotions employed by Groupon.

### The Information Landscape
#### Content frameworks
Cool and Belkin (2002) suggest an approach in which content is defined by three dimensions:

- Level: information, meta-information
- Medium: image, written text, speech, and so on
- Quantity: one object, set of objects, database of objects

#### Unstructured information
At the simplest level, this experience means **making the unstructured content searchable alongside the product records they support and presenting the results in a coordinated manner**. By selecting the appropriate tab, the user can pivot to a “Reviews View” that shows those same products displayed in list view with their associated customer reviews and ratings (Figure 3.11).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-11-9780123969811.jpg)

Figure 3.11 Moosejaw allows browsing of both product results and reviews.

A search for “fridge freezers” on electronics retailer Comet, for instance, returns a set of 273 products with 79 associated reviews. But this time, **the user can filter the product results using the review metadata**. For example, he or she can choose to see just those products that received five-star reviews from 25- to 34-year-old males in a “small family” (Figure 3.12).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-12-9780123969811.jpg)

Figure 3.12 Comet allows users to navigate products by review rating and reviewer profile.

**Unstructured content can lend itself to a more visual treatment, ranging from simple keyword tag clouds to more sophisticated charts and graphs**. Newssift (now closed) extracted named entities such as people, places, and organizations (shown in the middle three columns in Figure 3.13) and used various text analysis techniques to measure sentiment of the content, which it rendered using the pie chart on the left.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-13-9780123969811.jpg)

Figure 3.13 Newssift used natural language processing to identify named entities and sentiment.

Another way to improve the experience of searching unstructured content is to **organize the results into thematic clusters**. For example, the query “genesis” on the Metasearch engine Yippy returns a number of clusters based around themes such as religion, music, cars, and so on (shown in the left-hand panel of Figure 3.14).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-14-9780123969811.jpg)

Figure 3.14 Concept clusters for the query “genesis” on Yippy.

#### Aggregate information
In business intelligence and other analytics applications, for example, the goal is not so much to find individual records but to identify patterns of distribution across the collection as a whole.

In these and other analytic applications, the focus of the search experience shifts from finding and evaluating individual results to standing back and gaining a more `holistic understanding`.

Our visual system is hard-wired to perceive certain visual attributes without any conscious effort. These `preattentive attributes` include shape and color.

We can use this knowledge to our advantage in designing complex search applications, particularly those that involve the display of quantitative information (such as the Newssift example mentioned earlier). If we want to communicate certain patterns visually, or make them stand out from the background, we should use preattentive attributes. Figure 3.17 shows a more comprehensive list of such attributes that can be used in this manner (Few, 2004).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-17-9780123969811.jpg)

Figure 3.17 Preattentive attributes of visual perception.

However, not all attributes are created equal: some are more suited to the display of quantitative information than others (Cleveland and McGill, 1984). The relative strengths of the various preattentive attributes are indicated in Figure 3.18.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000033f03-18-9780123969811.jpg)

Figure 3.18 The accuracy of quantitative perception for various preattentive attributes.

## 4.Modes of Search and Discovery
![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-01-9780123969811.jpg)

Figure 4.1 Search involves the activities of information retrieval, analysis, and sensemaking.

### Search Modes and Frameworks
One of the key insights of Marcia Bates’ dynamic model (introduced in Chapter 2) is that information seeking is essentially a nonlinear process in which information needs are not satisfied by a single, ideal set of documents but by an aggregation of learning and insight gathered along the way. In subsequent work, Bates extended this framework to accommodate a more sophisticated set of activities, which she referred to as moves, tactics, stratagems and strategies (Bates, 1990), defined as follows:

- Move: an atomic thought or action, such as entering a particular keyword
- Tactic: a collection of moves, such as broadening a search through the use of a more generic keyword
- Stratagem: a composite of moves and/or tactics, such as identifying a promising information resource and scanning it for further relevant items
- Strategy: a plan for an entire search, consisting of moves, tactics and/or stratagems

O’Day and Jeffries, for example, examined the information seeking strategies employed by clients of information professionals, and identified three primary categories of search behavior (1993):

1. Monitoring a known topic or set of variables over time
2. Following a specific plan for information gathering
3. Exploring a topic in an undirected fashion

O’Day and Jeffries investigated search as a holistic process, integrating findability with analysis and sensemaking (as illustrated in Figure 4.1). As part of this research, they studied the analysis techniques employed by searchers in interpreting their results and identified six categories:

1. Looking for trends or correlations
2. Making comparisons
3. Experimenting with different aggregations/scaling
4. Identifying critical subsets
5. Making assessments
6. Interpreting data to find meaning

A further influential framework is that proposed by Gary Marchionini (2006), who developed a model consisting of three major categories of search activity: Lookup, Learn, and Investigate (Figure 4.2).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-02-9780123969811.jpg)

Figure 4.2 Marchionini’s taxonomy of search activities.

Joe Lamantia, for example, analyzed the behaviors of subscribers to a complex financial information service, and identified four primary modes of interaction (Lamantia, 2006):

- Seeking information: conventional keyword search, plus related activities such as faceted navigation
- Visiting stable destinations: accessing persistent resources or locations within the information space
- Monitoring notifications: maintaining awareness of events, activity, status, and so on
- Receiving delivered assets: accepting content via various channels, such as email, RSS, and others

Donna Spencer undertook a similar analysis (Spencer, 2006), inspired by the observation that the traditional information science framing of known item versus exploratory search did not adequately account for the behaviors she was witnessing in her work on designing intranets and complex websites. She observed that in many practical situations, “people didn’t necessarily know what they needed to know” and that much of the search behavior she was observing was actually concerned with trying to refind resources that had previously been discovered. From this observation, she proposed the following set of four search modes:

1. Known item: in which users know what they want, how to articulate it, and where to look
2. Exploratory: in which users have some idea of what they want, but not necessarily how to articulate it or where to look
3. Don’t know what you need to know: in which users may start with one particular goal in mind, but need to replace it with another if and when they discover some key insight
4. Refinding: in which users know what they want when they see it, but not necessarily how to articulate it or where to look

Item 3 suggests an intriguing possibility, encapsulating the activities and outcomes associated with the elusive quality we commonly refer to as `serendipity`.

In particular, we have studied user scenarios gathered during the development of numerous search and business intelligence applications (Russell-Rose, Lamantia, and Burrell, 2011), and from this derived a set of nine search modes.

These modes are shown in the following list, grouped according to the three top-level categories proposed by Marchionini (2006):

- Lookup
  - 1 Locate: To find a specific (possibly known) item
  - 2 Verify: To confirm that an item meets some specific, objective criterion
  - 3 Monitor: To maintain awareness of the status of an item for the purposes of management or control
- Learn
  - 4 Compare: To examine two or more items to identify similarities and differences
  - 5 Comprehend: To generate independent insight by interpreting patterns within a data set
  - 6 Explore: To investigate an item or data set for the purpose of knowledge discovery
- Investigate
  - 7 Analyze: To examine an item or data set to identify patterns and relationships
  - 8 Evaluate: To use judgement to determine the value of an item with respect to a specific goal
  - 9 Synthesize: To create a novel or composite artefact from diverse inputs

### Designing for Search Modes
#### Lookup: verify
In this mode, the user is inspecting a particular item and wishing to confirm that it meets some specific criterion. Google’s image results page provides a good example of this mode (Figure 4.3).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-03-9780123969811.jpg)

Figure 4.3 Google’s image results page supports verification of a specific item.

On mouse hover, the image is zoomed in to show a magnified version along with key metadata, such as filename, image size, caption, and source, which allows the user to verify the suitability of a specific result and either retrieve it there and then or rapidly switch to alternatives.

A similar example is provided by Netflix (Figure 4.4), which also supports a mouse rollover interaction on its result page. In this case, a dialog overlay is used to verify the film’s title and provide further key metadata in the form of a summary, credits, rating, and so on.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-04-9780123969811.jpg)

Figure 4.4 Netflix’s results page supports verification of specific film choices.

Alternatively, there may be cases in which the user needs to verify specific queries rather than search results. With its real-time feedback after every key press, Google Instant provides verification of the interpretation of the current query and the results that will be returned (Figure 4.5).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-05-9780123969811.jpg)

Figure 4.5 Google Instant provides support for verification of queries and results.

#### Learn: explore
A key part of exploring is **being able to distinguish between where you are going and where you have already been**.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-06-9780123969811.jpg)

Figure 4.6 Differentiating between visited and unvisited links aids exploration.

Amazon takes support for exploration a step further, through the use of components specifically designed to provide information regarding the user’s current location and previous navigational history. These include a Recent History panel, which shows the items recently viewed by the user (Figure 4.7) and a Recent Searches panel, in which the user can view or invoke any the queries previously issued in the current session (Figure 4.8). Along with the wishlist functionality, these components provide support for the “refinding” behavior identified by Donna Spencer.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-07-9780123969811.jpg)

Figure 4.7 Amazon supports exploration by showing recently viewed items.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-08-9780123969811.jpg)

Figure 4.8 Amazon supports exploration by showing recent searches.

Another simple technique for encouraging exploration is through the use of “see also” panels. An example of this usage can be seen at Food Network, where a query for “ice cream” returns featured videos and products from the Food Network store alongside the primary search results (Figure 4.9).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-09-9780123969811.jpg)

Figure 4.9 “See Also” panels support serendipitous browsing and exploration.

Beyond the page level, there is a further approach we can apply: changing the search paradigm itself. Consider the library site illustrated in Figure 4.10: it uses a `parametric` interface in which users are invited to enter values for each of the attributes in the dropdown menus, then click the search button.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-10-9780123969811.jpg)

Figure 4.10 Parametric search inhibits exploration.

Consider the library site shown in Figure 4.11. In this instance, they have adopted a `faceted` approach, in which the attributes are not hidden behind dropdown menus but displayed as links in a navigational menu. This approach enables users to intuitively explore by progressively refining their choices in each dimension.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-11-9780123969811.jpg)

Figure 4.11 Faceted search facilitates exploration.

#### Investigate: analyze
A simple example of support for this can be found at Google patents (Figures 4.12a and 4.12b). The alternate views (Grid View and List View) allow the user to switch between rapid exploration (scanning titles, browsing thumbnails, looking for information scent) and a more detailed analysis of each record and its metadata.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-12-9780123969811.jpg)

Figure 4.12a, b Alternate views at Google Patents support mode switching between exploration and analysis.

He now wishes to analyze some of the prior art associated with a particular technology and understand how it has been reported in the media. He may turn to a news aggregator site such as the now-defunct Newssift.com (which was in its time a unique resource—see Figure 4.13).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-13-9780123969811.jpg)

Figure 4.13 Support for analysis at Newssift.com.

### Mode Chains and Patterns
Five example mode chains from the domain of enterprise search are listed here, with an associated example scenario (Russell-Rose, Lamantia, & Burrell, 2011):

1. Comparison-Driven Search (Analyze-Compare-Evaluate): “Replace a problematic part with an equivalent or better part without compromising quality and cost”
2. Exploration-Driven Search (Explore-Analyze-Evaluate): “Identify opportunities to optimize use of tooling capacity for my commodity/parts”
3. Strategic Insight (Analyze-Comprehend-Evaluate): “Understand a lead’s underlying positions so that I can assess the quality of the investment opportunity”
4. Strategic Oversight (Monitor-Analyze-Evaluate): “Monitor and assess commodity status against strategy/target”
5. Comparison-Driven Synthesis (Analyze-Compare-Synthesize): “Analyze and understand market trends to inform brand strategy and communications plan”

We can represent this grammar visually, as in Figure 4.14, which shows how the various sequences combine to form a “mode network.”

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000045f04-14-9780123969811.jpg)

Figure 4.14 A network of search modes.

### Designing for Mode Chains
Our experience suggests both the existence of repeatable patterns in information seeking behavior and the potential to apply these patterns as a framework for the design of search experiences (Russell-Rose, Lamantia, & Burrell, 2011). The implications of such a grammar could be considered at three levels of abstraction:

- A single functional element
- A complete screen composed of multiple functional elements
- An integrated application composed of multiple screens

# 2.Design Solutions
## 5.Formulating the Query
### Entering the Query
#### The search box
One of the fundamental concepts in human–computer interaction (HCI) is the notion of `affordance`: the idea that an object’s design should suggest the interactions that its `function` supports.

Likewise, the design of the search box should follow its function. If its purpose is to allow the user to enter queries in the form of keywords, then it should look like it will accept textual input and have an associated button that clearly indicates its function, as in Figure 5.1. The examples in Figure 5.2, by contrast, are less functional. The search box should also be wide enough to avoid obscuring parts of the query: Jakob Nielsen suggests that a minimum of 27 characters is required to accommodate 90 percent of queries (Nielsen & Loranger 2006).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-01-9780123969811.jpg)

Figure 5.1 A match between form and function at eBags.com.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-02-9780123969811.jpg)

Figure 5.2 Less conventional search box designs.

On the web, users can search for almost anything, with few constraints over topic or medium. By contrast, in site search (i.e., search of a specific website), the choices are usually much more restricted, which presents an opportunity to provide further support in the form of “placeholder” text and other prompts to help users construct meaningful queries.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-07-9780123969811.jpg)

Figure 5.7 Pipl search box guides users toward meaningful queries.

#### Scoped search
![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-08-9780123969811.jpg)

Figure 5.8 Search can be restricted to a specific category on eBay.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-09-9780123969811.jpg)

Figure 5.9 Scoped search at classified advertisement site Craigslist.

Users with high `domain expertise` (see Chapter 1) can therefore benefit greatly from scoped search, particularly if they are seeking known items.

#### Search within
By allowing users to search within an existing set of results, the query acts as a kind of refinement, narrowing down the results in a manner similar to that of faceted navigation (see Chapter 7).

For this reason, search within is often presented as a dedicated search box within the faceted navigation menu (Figure 5.11).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-11-9780123969811.jpg)

Figure 5.11 Search within is part of the faceted navigation menu at dabs.com.

Alternatively, search within can be integrated with the standard search box, using a radio button or checkbox to toggle between the two different types of input (Figure 5.12).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-12-9780123969811.jpg)

Figure 5.12 Search within is invoked using a checkbox at bulbs.com.

#### Advanced search
When `parametric` search was originally conceived, its interaction was based around the notion of selecting parameters on an extended form. In this context, it may have made sense to withhold some choices from the default view and present them instead as an advanced option (Figure 5.14).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-14-9780123969811.jpg)

Figure 5.14 Advanced search form at WARC.

#### Beyond keywords
##### Natural language
One of the most intuitive is to express the query as you would to another human being, that is, as a natural language question or request. This kind of interaction was popularized by search engines such as Ask (formerly Ask Jeeves), which uses a combination of text analytics and human moderation to produce a question-answering search experience (Figure 5.15).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-15-9780123969811.jpg)

Figure 5.15 Natural language question answering at Ask.

Wolfram Alpha uses NLP to answer factual queries by computing answers and relevant visualizations from a knowledge base of curated, structured data (Figure 5.16).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-16-9780123969811.jpg)

Figure 5.16 Natural language question answering at Wolfram Alpha.

##### Nontext queries
![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-17-9780123969811.jpg)

Figure 5.17 Search by example using images at Google.

Each of these services represents a type of search known as `query by example`.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-18-9780123969811.jpg)

Figure 5.18 Search by color at Etsy.

### Refining the Query
#### Autocomplete
One of the key principles in human–computer interaction is `recognition over recall`: the notion that people are better at recognizing things they have previously experienced than they are at recalling them from memory. 

Autocomplete transforms a recall problem into one of recognition.

The UK’s National Rail website in Figure 5.19, for example, recalls the railway stations that match a handful of characters.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-19-9780123969811.jpg)

Figure 5.19 Autocomplete at the UK National Rail Enquiries website.

Autocomplete does its best to remain unobtrusive: we can still enter a query in full if we choose. But by selecting the completions, we save time and keystrokes. Moreover, they help us avoid spelling mistakes. On smartphones and tablets, autocomplete is applied to all manner of applications from text messaging to email (Figure 5.20).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-20-9780123969811.jpg)

Figure 5.20 Autocomplete is used for SMS and email on the iPhone.

Autocomplete makes the most sense when the choices are based on a `controlled vocabulary`—that is, a finite list of items, such as a directory of names, locations, organizations, and so on.

#### Autosuggest
The purpose of autocomplete is to search within a controlled vocabulary for entries matching a partial character string. By contrast, the purpose of autosuggest is to search within a virtually unbounded list for related keywords and phrases (which need not match the exact query string). Autocomplete helps us get an idea out of our head and into the search box; autosuggest actually throws new ideas into the mix. In this respect, autosuggest operates at a more conceptual level, offering choices where the relationship to the query may go beyond simple string matching. Both techniques save keystrokes and help us avoid spelling mistakes, but autosuggest can also help us construct a more useful query than we might otherwise have thought of on our own. eBay, for example, provides a variety of different suggestions related to the query “guitar,” highlighting the matching terms in blue (Figure 5.21).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-21-9780123969811.jpg)

Figure 5.21 Autosuggest at eBay.

Home Depot, for example, provides a particularly extensive autosuggest function, consisting of product categories, buying guides, project guides, and more (Figure 5.22). Not only do these suggestions facilitate known-item search, but they also support exploratory search behavior, encouraging the user to discover new product ideas and specialist content.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-22-9780123969811.jpg)

Figure 5.22 Autosuggest supports known-item and exploratory search at Home Depot.

In contrast to eBay, Yahoo emphasizes the ways in which the query may be extended by highlighting the `nonmatching terms` (Figure 5.23).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-23-9780123969811.jpg)

Figure 5.23 Autosuggest offers query refinements and content suggestions at Yahoo.

A further technique to optimize the value of query suggestions is to display them in the context of recent searches. One approach, which Safari utilizes, is to simply present two adjacent groups: one for query suggestions and another for the browser’s search history (Figure 5.24).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-24-9780123969811.jpg)

Figure 5.24 Query suggestions are presented alongside recent searches in Safari on the iPad.

#### Instant results
Autocomplete and autosuggest are both valuable techniques to help us conceive and articulate more effective queries. They differ in approach but share the principle that as-you-type suggestions provide a shortcut from query to search results. But in some cases, it is possible to go even further by offering actual results rather than just query reformulations. For example, if we type the characters “ip” into the search box at Apple.com, six items appear (Figure 5.25). However, if we select one of these, it bypasses the search results page entirely and takes us directly to a product-specific landing page. Rather than suggesting alternative queries, the search box provides “instant results” in the form of a set of matching “best bets” for products and resources.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-25-9780123969811.jpg)

Figure 5.25 Instant results at Apple.com.

In Windows 7, for example, a keyword search invokes a panel of recommended results grouped into popular categories (Figure 5.26). We can either select one directly to open it, or choose the “See more results” option to open a regular search results page.

Figure 5.26 Instant results in Windows 7 desktop search.

Google provides its own type of “instant results,” which complement their autosuggest function to provide a highly responsive search experience. Instead of presenting a static page of results after each query, Google Instant updates the search results in real time as each character is entered. If we don’t see the results we want, we can just keep typing and watch the results update (Figure 5.27).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-27-9780123969811.jpg)

Figure 5.27 Instant results when searching via Google.

### Keeping on Track
#### Did you mean
One of the simplest is to use spell checking algorithms to compare queries against common spellings of each word. For example, Figure 5.28 shows the results on Google for the query “expolsion.” This isn’t necessarily a “failed” search (it does return results), but the more common spelling “explosion” would return a more productive result set.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-28-9780123969811.jpg)

Figure 5.28 Potential spelling mistakes are addressed by a “Did you mean” suggestion at Google.

Amazon and eBay both conservatively apply “did you mean” to queries such as “guitr,” faithfully passing on the results for this query but offering the alternative as a highlighted suggestion immediately above the search results (Figures 5.29 and 5.30). And in Amazon’s case, the results for the corrected spelling are appended immediately below those of the original query.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-29-9780123969811.jpg)

Figure 5.29 “Did you mean” at Amazon.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-30-9780123969811.jpg)

Figure 5.30 “Did you mean” at eBay.

#### Autocorrect
However, there are times when it is possible to be more certain that a spelling mistake has occurred.

For example, consider a query for “expolson” on Google: this time, instead of applying a “did you mean,” it is autocorrected to “explosion” (Figure 5.31). As before, a message appears above the results (“Showing results for”), but this time the choice has been made for them.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-31-9780123969811.jpg)

Figure 5.31 Autocorrect at Google.

#### Partial matches
Amazon provides a particularly effective implementation of this strategy. For example, a keyword search for “fender strat maple 1976 USA” finds no matching results. However, rather than returning a zero results page, Amazon returns a number of partial matches based on various keyword permutations (Figure 5.33). Moreover, by communicating the nonmatching elements of the query (using strikethrough text), it gently guides us along the path to more informed query reformulation.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-33-9780123969811.jpg)

Figure 5.33 Partial matches at Amazon.

A similar strategy can be seen at eBay, which also finds no results for the same query we tried on Amazon. Instead of a zero results page, we see a list of the partial matches with an invitation to select one of them (or to “try the search again with fewer keywords”). These are ordered using what’s known as quorum-level ranking (Salton, 1989), which sorts results according to the number of matching keywords (Figure 5.34). Thus products matching four keywords (such as “fender strat maple USA”) are ranked above those containing three or fewer (such as “fender strat USA”).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-34-9780123969811.jpg)

Figure 5.34 Partial matches using quorum-level ranking at eBay.

#### Related searches
![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-35-9780123969811.jpg)

Figure 5.35 Related searches at Bing.

Google, by contrast, shows them on demand (via a link in the sidebar) as a panel above the main search results (Figure 5.36). 

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-36-9780123969811.jpg)

Figure 5.36 Related searches at Google.

Apart from providing inspiration, related searches can be used to help clarify an ambiguous query (see Chapter 7 for the significance of this within faceted search). For example, query on Bing for “apple” returns results associated mainly with the computer manufacturer, but the related searches clearly indicate a number of other interpretations (Figure 5.37).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-37-9780123969811.jpg)

Figure 5.37 Query disambiguation via related searches at Bing.

Related searches can also be used to articulate associated concepts in a taxonomy. At eBay, for example, a query for “acoustic guitar” returns a number of related searches at varying levels of specificity. These include subordinate (child) concepts, such as “yamaha acoustic guitar” and “fender acoustic guitar,” along with sibling concepts such as “electric guitar,” and superordinate (parent) concepts such as “guitar.” These taxonomic signposts offer a subtle form of guidance, helping us understand better the conceptual space in which our query belongs (Figure 5.38).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-38-9780123969811.jpg)

Figure 5.38 Taxonomic signposting via related searches at eBay.

Sometimes it is the results themselves that provide the stimulus. When we find a particularly good match for our information need, we try to find more of the same: a process that Peter Morville refers to as “pearl growing” (Morville, 2010). Google’s image search, for example, offers us the opportunity to find images similar to a particular result (Figure 5.39).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-39-9780123969811.jpg)

Figure 5.39 Find similar images at Google.

Recommender systems such as Last.fm and Netflix rely heavily on attributes, ratings, and collaborative filtering data to suggest content we’re likely to enjoy. And from just a single item in our music collection, iTunes Genius can recommend many more for us to listen to as part of a playlist (Figure 5.40).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000057f05-40-9780123969811.jpg)

Figure 5.40 Genius playlist creates “more like this” from a single item.

## 6.Displaying and Manipulating Results
### Displaying Search Results
#### Basic principles
To illustrate, suppose you’re looking for a new job role, and you browse to the 40 or so open positions listed on UsabilityNews (Figure 6.1). The results are displayed in concise groups of ten, occupying minimal screen space. But can you tell which particular ones might be worth pursuing? The roles all sound quite similar (and job titles can be misleading anyway). Closing dates seem largely irrelevant, unless we already have a particular position in mind. The end result is a weak information scent (see Chapter 2) that forces us to continually jump back and forth between the individual results and the list to see the information we need. Some degree of movement like this may be inevitable with any design, but when it becomes chronic, it is referred to as `pogosticking` (Spool, 2005).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-01-9780123969811.jpg)

Figure 6.1 Weak information scent in the job listings at UsabilityNews.

What we need instead is information that allows us to make a more informed judgment regarding the suitability of each position: details such as location, remuneration, role description, and so on. A similar search on recruitment agency Reed offers all of these, along with associated tools and controls (Figure 6.2).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-02-9780123969811.jpg)

Figure 6.2 More informative job listings at Reed.

Of course, the corollary is that each item occupies more screen space, and thus fewer results can be shown `above the fold` (i.e., in the area that is visible without scrolling). This setup increases the likelihood that potentially valuable results will be overlooked, particularly if relevance appears to be weaker further down the list. An acute example can be found at electrical retailer Comet, where each individual result extends to over 300 pixels in height (Figure 6.3). Consequently, in many cases it is not possible to view more than two or three results at any one time. In practice, we need a balance that addresses the users’ characteristics (Chapter 1), their information seeking behavior (Chapter 2), and the broader search context (see Chapter 3).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-03-9780123969811.jpg)

Figure 6.3 Highly detailed product listings at Comet.

#### The anatomy of a search result
The three major web search engines are remarkably consistent (Figure 6.4). By default, each displays the page title, the URL (in abbreviated form), and an informative summary of the content (known as a “snippet”).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-04-9780123969811.jpg)

Figure 6.4 Commonality of design for the major web search engines.

The order of the components is subtly different: Google displays the URL immediately below the title, perhaps reflecting its value to users in making trust and credibility judgments (Schwarz & Morris, 2011). But one feature they all share is the use of `query-oriented summaries`: snippets that show the query terms in context (Tombros & Sanderson, 1998). In addition, these summaries highlight the matching terms (using boldface), which has the effect of drawing attention to key fragments in the text and communicating how closely the query terms appear to one another (Marchionini, 1995). This is known to be a strong indicator of relevance (Muramatsu & Pratt, 2001).

And for mobile, almost everything changes. First, it is important to keep the snippets short. But more important, we need results that reflect our spatial location (see Chapter 3). Here, maps become the natural medium for search results, placing each result in its geospatial context (Figure 6.5).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-05-9780123969811.jpg)

Figure 6.5 Search results as map locations in the mobile context.

But search results don’t have to be text at all. If our goal is to refind a previously known item, it may be quicker for us to view them as a set of thumbnails, flicking through them in sequence (Figure 6.6). When we know exactly what our target looks like, we can rely on recognition rather than recall to find it (see Chapter 5).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-06-9780123969811.jpg)

Figure 6.6 Search results displayed as thumbnails on Google mobile web.

By offering `deep links` to key pages within popular sites, the major web search engines invite us to skip home pages and navigate direct to content that would otherwise be buried deep within a site’s structure (Figure 6.7).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-07-9780123969811.jpg)

Figure 6.7 Deep links in search results at Yahoo.

#### Search result previews
`Previews` allow us to see the detail of an individual item within the context of the search results page.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-08-9780123969811.jpg)

Figure 6.8 Search result previews at Bing.

In providing a convenient, lightweight method for verifying individual items, previews offer direct support for one of the key search modes discussed in Chapter 3.

#### Answers and shortcuts
Google, for example, allows us to ask direct questions in a variety of forms. When it recognizes the presence of certain trigger words, it responds with weather forecasts, stock quotes, maps, and sports scores (Figure 6.9). We can even track parcels, convert currencies and ask it to perform all manner of numeric calculations and conversions. In this context, the boundary between search and question answering becomes blurred, with the search box presenting a command-line style of interface to those who can exploit its power and flexibility (Morville, 2010).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-09-9780123969811.jpg)

Figure 6.9 Direct answers for focused information needs at Google.

Wolfram Alpha extends the concept further still. With graphs, charts, tables, and visualizations all within its repertoire, it chooses the right format for our specific information needs (Figure 6.10). This type of interaction extends the concept of search beyond findability and into a new territory of computational knowledge and inference.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-10-9780123969811.jpg)

Figure 6.10 Beyond traditional search results at Wolfram Alpha.

At Google, for example, we can recommend a particular result and share it with colleagues by using the “+1” button (Figure 6.11).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-11-9780123969811.jpg)

Figure 6.11 Recommending a search result at Google.

At the BBC, we can play video and audio clips with a single click (Figure 6.12).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-12-9780123969811.jpg)

Figure 6.12 Content can be played directly from the results page at BBC.

Similarly, on iPad and iPhone, we can use Spotlight to search across all our data (Figure 6.13). But the results are more than just placeholders for files: they are `actionable objects`, offering a direct invitation to play content, make phone calls, or launch applications. In this respect, actionable results provide a bridge to the broader task context of search, helping us progress from finding information to completing goals.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-13-9780123969811.jpg)

Figure 6.13 Spotlight search provides actionable objects as results.

### Search Results Pages
#### Basic principles
Even Google, with its minimalist home page design, manages to pack more than a dozen separate features into its default search results page (Figure 6.14). These can be grouped according their function, such as input, informational, control, or personalization (Wilson, 2011):

- Input features
  - Search box including auto-suggest and instant results (on character input)
- Informational features
  - Number of results found
  - Support for query reformulation (“did you mean” and autocorrect)
  - Individual results consisting of:
    - Hyperlinked titles with snippets and URLs
    - Page preview (available on hover)
    - Related metadata, such as previous visits, citations, related articles, and social data (such as page sharing by colleagues)
  - Related searches
  - Sponsored links (advertisements)
- Control features
  - Faceted navigation menu (for content type, date, etc.)
  - Search tools menu (sites with images, visited pages, etc.)
  - Pagination
  - Options for advanced search and help
- Personalization features (when logged in)
  - Profile, settings, notifications, etc.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-14-9780123969811.jpg)

Figure 6.14 Minimalist design belies feature-rich complexity in Google’s SERPs.

As shown in Chapter 5, `query reformulation` is a critical step in many information journeys. In fact, this principle is so fundamental that we often take it for granted, and it becomes conspicuous only by its absence: faced with the response shown in Figure 6.15, can you work out what the query was or how best to reformulate it? In this instance, the user is forced to rely on recall rather than recognition, contrary to the principles outlined in Chapter 5.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-15-9780123969811.jpg)

Figure 6.15 Smashing Magazine’s SERP lacks the context necessary for effective query reformulation.

A second, related principle is to maintain the context of the current search by displaying the number of matching results. This deceptively simple measure plays a vital role in the information seeking dialogue, as it communicates the magnitude of the current information space and helps the user make more informed query reformulations.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-16-9780123969811.jpg)

Figure 6.16 The iTunes app shows the number of matching results in context.

Web search engine DuckDuckGo makes a virtue of this: a search for “apple,” for example, returns results for all the major senses in the first few results (Figure 6.17). Moreover, it also displays an explicit clarification panel, showing the alternative meanings and offering users the opportunity to clarify their intent. As we will see in Chapter 7, this is a pivotal point in the search experience, when users are invited to explore the subtleties of their information need, and engage in a dialogue that allows them to build their own mental map of the information landscape.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-17-9780123969811.jpg)

Figure 6.17 Clarifying our information need at DuckDuckGo.

Amazon uses this concept to good effect, presenting several alternative interpretations on the first page for an ambiguous query such as “washer” (Figure 6.18).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-18-9780123969811.jpg)

Figure 6.18 Diversity of search results at Amazon.

#### Page layouts
In fact, in some environments, it makes more sense to allow users to browse products visually, laying out the results in a two-dimensional grid. This type of `“gallery”` layout is commonly seen in online retail, with each result displayed in a more concise, pictorial form facilitating rapid visual scanning (Figure 6.19). This type of view supports the search modes of exploring and locating that were discussed in Chapter 4.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-19-9780123969811.jpg)

Figure 6.19 Gallery view at eBay.

The ideal layout will depend on the particular result set: those items for which appearance is important (e.g., cars, clothing) are naturally suited to a visually oriented layout, whereas others (e.g., computers, electrical goods) may be better suited to a detail-oriented layout. For this reason, it is common to see a control allowing users to switch between views (see top left of Figure 6.19).

Although list and gallery view are popular configurations, they are by no means the only options. Complex products such as electrical components may be more meaningfully viewed using a display that exposes the full detail of their specification, allowing rapid scanning and comparison of their individual attributes (Figure 6.20). This type of view supports key search modes such as analyzing and comparing (see Chapter 4).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-20-9780123969811.jpg)

Figure 6.20 Parametric view at RS Components.

In some search contexts, the results may have a geospatial element to them. In this case, the most natural layout is to present them as a two-dimensional map.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-21-9780123969811.jpg)

Figure 6.21 Search results are shown in map view on Google mobile.

Carrot2 takes the concept further still, offering a choice of visualizations (Figure 6.22). This approach allows users to gain an impression of the overall themes within the results and explore similar results together within a single group.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-22-9780123969811.jpg)

Figure 6.22 Search results are clustered by topic at Carrot2.

#### Blended results
The Guardian newspaper, for example, shows results laid out in vertical list (Figure 6.23) but grouped according to category (editor’s picks, tags, most recent articles, etc.).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-23-9780123969811.jpg)

Figure 6.23 Search results are grouped vertically by type at the Guardian.

A query for “jets” on Google, for example, returns sports scores, news items, web pages and more. However, unlike the previous example, these are displayed in an undifferentiated vertical list (Figure 6.24).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-24-9780123969811.jpg)

Figure 6.24 Blended search results and media types at Google.

By contrast, business information provider Reuters groups search results according to medium (news, blogs, video, or pictures), which it displays in separate panels (Figure 6.25). News items take precedence as the default shown in the main panel, but this display can be replaced by another content type by selecting the appropriate tab.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-25-9780123969811.jpg)

Figure 6.25 Search results are grouped by medium at Reuters.

Apple’s iTunes store (Figure 6.26) takes the structured approach a step further, displaying a variety of content types on the SERP as actionable objects (see “Displaying Search Results” earlier in this chapter) in individual panels with custom controls (see “Manipulating Search Results” later in this chapter).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-26-9780123969811.jpg)

Figure 6.26 Varied content types displayed in individual panels with custom controls at the iTunes Store.

At the Food Network, for example, the primary content consists of recipes, but the SERP also promotes related content in the form of videos and products from the Food Network store, using a sidebar on the right-hand side (Figure 6.27).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-27-9780123969811.jpg)

Figure 6.27 Promotion of related content and products at the Food Network.

#### Zero results pages
Apple Store, which provides basic advice but misses the opportunity to provide direct support (Figure 6.28).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-28-9780123969811.jpg)

Figure 6.28 Limited support for query reformulation on the Apple Store zero results page.

Classified ad site Carzone, by contrast, gives clear messaging and useful advice and also provides the means to address the issue by removing the nonmatching search criteria (Figure 6.29).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-29-9780123969811.jpg)

Figure 6.29 Direct support for query reformulation on the Carzone zero results page.

### Manipulating Search Results
#### Pagination
Pagination confers several benefits: it limits load time (by dividing the results into manageable ‘chunks’); it provides a measure of how far through the set the user has progressed; and it shows how much further they can go. Implementations vary considerably, with Google, Bing, and Yahoo all offering their own distinctive interpretations (Figure 6.30). 

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-30-9780123969811.jpg)

Figure 6.30 Varying implementations of pagination at Google, Bing, and Yahoo (desktop).

These implementations differ further when applied to the mobile context (Figure 6.31). Google, for example, maintains consistency with the desktop by using a control that differs little in behavior; loading a further ten results each time. Bing, by contrast, offers a link to “more results,” which returns a further page of results that load on demand. This design means that the user can simply scroll to the bottom and the next set of results will be appended, without reloading the page. A similar approach is seen at Yahoo, in which ten additional results are appended to the current set on each invocation of the “Show more web results …” button.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-31-9780123969811.jpg)

Figure 6.31 Varying implementations of pagination at Google, Bing, and Yahoo (mobile).

#### Sorting and filtering
Sort options such as these are commonly implemented using a dropdown control, which allows the user to apply different sort keys (Figure 6.33).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-33-9780123969811.jpg)

Figure 6.33a, b, and c Drop down controls for sorting at Walmart, Amazon, and Littlewoods.

A kind of hybrid example of sorting and filtering (and pagination) can be seen at the iPhone App Store (Figure 6.36). Here, content is grouped into various default categories to facilitate browsing along various popular dimensions (such as Top Paid, Top Free, etc.).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-36-9780123969811.jpg)

Figure 6.36 Button controls for sorting on the iPhone App Store.

A more mainstream use of filtering is to allow users to refine their results by one or more independent dimensions or facets. This approach, known as `faceted search`, has become the dominant paradigm among online retail and many other commercial search applications.

#### Query clarification
There are a number of approaches to query clarification. One of the most common is to display the alternative interpretations in the form of matching categories and invite users to choose a more precise category for their information need. Amazon, for example, does this is in a subtle manner. A query here for “mp3” returns several million results, including players, accessories, and content on the first page (along with best bets such as a promotion for the Amazon MP3 store and featured results for the Electronics Store). However, the primary navigation option in the left hand menu is a `category selector` (Figure 6.37). 

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-37-9780123969811.jpg)

Figure 6.37 Query clarification by category selection at Amazon.

A more conspicuous variant can be seen at electrical retailer Comet. As expected, an ambiguous query here such as “washer” returns a mixed set of results. However, this time the category selector is displayed much more prominently, directly above the search results (Figure 6.38).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-38-9780123969811.jpg)

Figure 6.38 Prominent category selection at Amazon.

#### Comparing
A common approach is to provide access to what is popularly known as a comparison view. Computing equipment retailer Dabs, for example, provides a column of checkboxes next to each search result, which marks items for comparison (Figure 6.42).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-42-9780123969811.jpg)

Figure 6.42 Selecting items for comparison at Dabs.

Selecting a “Compare” button at the head of the column opens a separate view that shows the full detail of each item in a separate column, enabling easy comparison of the individual product attributes (Figure 6.43).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-43-9780123969811.jpg)

Figure 6.43 Product comparison at Dabs.

Online retailer Best Buy, for example, shows both the size limit and the current state of the comparison view using a dynamically updating preview (Figure 6.44).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-44-9780123969811.jpg)

Figure 6.44 Selecting items for comparison at Best Buy.

The goal of the comparison page is, of course, to support `analyzing` and `comparing` individual products. Best Buy offers further support for these search modes by organizing the attributes into logical groups and providing an option to automatically highlight the differences between products (Figure 6.45).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000069f06-45-9780123969811.jpg)

Figure 6.45 Highlighting differences between products at Best Buy.

## 7.Faceted Search
### Definitions
`Facets` are essentially independent properties or `dimensions` by which we can classify an object. For instance, a book might be classified using an Author facet, a Subject facet, and a Date facet. `Faceted navigation` enables users to explore information spaces by progressively refining their choices in each dimension. For example, we could explore a collection of books by selecting a specific author, subject, or date range. Selections are made by applying facet values, which determine the current results set. The set of selections active at any given time is known as the `navigational context`, which corresponds to the user’s current location in the information space. `Faceted search` is then the combination of faceted navigation with other forms of search (such as those discussed in Chapter 5).

A key principle of faceted search is to minimize the likelihood of zero results by guiding users toward productive navigational choices.

#### Facet semantics
Facets can be either `single-select` or `multi-select`.

Multi-select facets can either be `multi-select OR` or `multi-select AND`.

#### Facet states and behaviors
By convention, values applied `across` different facets are normally applied conjunctively (e.g., Author = Russell-Rose AND Subject = Search AND Date = 2012) whereas values applied `within` a given facet are normally applied disjunctively (e.g., Date = 2010 OR Date = 2011 OR Date = 2012).

### Layout
#### Vertical layout
An example of this configuration (from eBay) is shown in Figure 7.1.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-01-9780123969811.jpg)

Figure 7.1 Vertical stack faceted navigation at eBay.

However, a number of sites have chosen to locate the facets on the right, including Edinburgh University’s library catalogue (Figure 7.2), although the motivation for placing the facets on the right in this case may simply be to direct attention to the “concept browser” control on the left.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-02-9780123969811.jpg)

Figure 7.2 Facets on the right at Edinburgh University Library.

#### Horizontal layout
An alternative to vertical layout is to arrange the facets horizontally, usually across the top of the page as shown at Yelp in Figure 7.3.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-03-9780123969811.jpg)

Figure 7.3 Horizontal facets at Yelp.

Figure 7.4 shows a search for “connectors” that returns 25 facets displayed in alphabetically ordered, scrollable containers (with the results pushed below the fold).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-04-9780123969811.jpg)

Figure 7.4 Facets wrap across the page at Amphenol.

#### Hybrid layout
A few, however, adopt a hybrid approach, such as TravelMatch (Figure 7.5).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-05-9780123969811.jpg)

Figure 7.5 Hybrid layout at TravelMatch.

### Default State
#### Closed by default
The first option is to display all facets as closed by default, which is the approach adopted by TravelMatch in the left-hand menu in Figure 7.5. The advantage is that it uses minimal screen space, and for sites with a large number of facets (such as this), the visibility of that breadth of choice is maximized. The disadvantage is that the information scent offered by each facet is weaker than if they were shown in their open state, with sample facet values clearly visible. As a result, adoption and usage of the facets may be compromised. To mitigate this, the invitation or control to open (and close) each of the facets should be clearly visible and unambiguous.

#### Open by default
The second option is to display all facets in their open state by default, which maximizes the information scent by exposing example values for each of the facets and helps encourage adoption and usage of the faceted menu. An example of this approach can be seen at the job site Monster (Figure 7.6).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-06-9780123969811.jpg)

Figure 7.6 Facets open by default at Monster.

#### Open/closed hybrid
This option is becoming increasingly popular, as it makes efficient use of screen space and provides a stronger information scent for the first few facets (which should ideally be sorted by priority). An example of this can be seen below at NCSU Libraries (Figure 7.7).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-07-9780123969811.jpg)

Figure 7.7 Open and closed facets at NCSU Libraries.

For more complex search scenarios, a mixed initiative approach may be adopted. For example, a search on eBay using the query “golf” returns a `query clarification` dialogue (see Chapter 6), as shown in Figure 7.8.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-08-9780123969811.jpg)

Figure 7.8 Facets open for query disambiguation at eBay.

But once a selection has been made, a different approach is adopted. For example, if we select Category=“Cars, Motorcycles & Vehicles”, we are presented with a refined set of results and further facets, as shown in Figure 7.9.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-09-9780123969811.jpg)

Figure 7.9 Facets now open and closed at eBay.

### Display Formats
#### Hyperlinks
They represent textual values simply and directly and afford interaction through direct selection (e.g., a single mouse click). When combined with `record counts` (i.e., the number of items matching each facet value), they provide a simple but effective summary of the information space (Yee et al., 2003).

The example from the Food Network shows a typical faceted navigation menu, with ten facets containing textual values that are displayed as hyperlinks (Figure 7.10).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-10-9780123969811.jpg)

Figure 7.10 Hyperlink facets at the Food Network.

We see such an example at NCSU libraries (Figure 7.11). In this example, the user can select `multiple` Subjects, Genres, Formats, and so on, and these are added to the navigational context each time.

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-11-9780123969811.jpg)

Figure 7.11 Hyperlink facets at NCSU Libraries.

#### Checkboxes
Checkboxes are an ideal format for the display of `multi-select facets`. An example of their use can be found at many sites, including eBay (Figure 7.12).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-12-9780123969811.jpg)

Figure 7.12 Checkbox facets at eBay.

#### Range sliders
In the previous examples, the facet values are `categorical` in nature—qualitative data organized on a `nominal` or `ordinal` scale. But facets often need to display `quantitative` data, such as price ranges, product sizes, date ranges, and so on. In such cases, a range slider is often a more suitable display mechanism. An example can be found at Molecular’s Wine Store (Figure 7.13).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-13-9780123969811.jpg)

Figure 7.13 Range sliders at Molecular.

#### Input boxes
An example of this can be seen at Glimpse.com, where specifying an exact price range for shoes is much easier using the input boxes than the slider (Figure 7.14).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-14-9780123969811.jpg)

Figure 7.14 Input boxes at Glimpse.

For example, quantitative data can be transformed into an `interval scale` by subdividing the range into a sequence of smaller ranges and giving each a label. This is the approach taken by Amazon in their treatment of price ranges (Figure 7.15).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-15-9780123969811.jpg)

Figure 7.15 Interval scales at Amazon.

#### Color pickers
Littlewoods, for example, displays a color swatch with corresponding text labels and shows only values that are specific to the current result set (Figure 7.16).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-16-9780123969811.jpg)

Figure 7.16 Color picker at Littlewoods.

Artist Rising, by contrast, uses a generic color picker, offering a choice across the entire color spectrum (Figure 7.17).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-17-9780123969811.jpg)

Figure 7.17 Color picker at Artist Rising.

#### Tag clouds
An example can be found at Artist Rising, which displays a tag cloud as an overlay within a horizontal faceted menu (Figure 7.18).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-18-9780123969811.jpg)

Figure 7.18 Tag clouds at Artist Rising.

A somewhat different treatment can be found at PC Authority, which uses tag clouds to present terms extracted from unstructured content (i.e., text documents). These are displayed in a separate container that is disconnected (conceptually and physically) from the left-hand faceted navigation menu. As tags are selected, they are added to the breadbox alongside other refinements (Figure 7.19).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-19-9780123969811.jpg)

Figure 7.19 Tag clouds at PC Authority.

#### Data visualizations
Applications such as these are designed to `aggregate`, `organize`, and `summarize` data from numerous `quantitative` and `qualitative` sources by using data visualizations to communicate key metrics, patterns, and overall status. An example of such a visualization could be found at Newssift, in which pie charts were used to communicate the distribution of article sources and associated sentiment (Figure 7.20).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-20-9780123969811.jpg)

Figure 7.20 Data visualizations at Newssift.

Another use of data visualization in faceted search is to communicate patterns in geospatial data. An example of this can be found at WITS (the Worldwide Incidents Tracking System), which uses various forms of visualization to display terrorist incidents overlaid on a map of the world (Figure 7.21).

![](https://learning.oreilly.com/library/view/designing-the-search/9780123969811/images/F000070f07-21-9780123969811.jpg)

Figure 7.21 Data visualization at WITS.

### Showing Additional Values












